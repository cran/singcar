<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />



<title>The R package singcar: Comparing Single Cases to Small Samples</title>

<script src="data:application/javascript;base64,Ly8gUGFuZG9jIDIuOSBhZGRzIGF0dHJpYnV0ZXMgb24gYm90aCBoZWFkZXIgYW5kIGRpdi4gV2UgcmVtb3ZlIHRoZSBmb3JtZXIgKHRvCi8vIGJlIGNvbXBhdGlibGUgd2l0aCB0aGUgYmVoYXZpb3Igb2YgUGFuZG9jIDwgMi44KS4KZG9jdW1lbnQuYWRkRXZlbnRMaXN0ZW5lcignRE9NQ29udGVudExvYWRlZCcsIGZ1bmN0aW9uKGUpIHsKICB2YXIgaHMgPSBkb2N1bWVudC5xdWVyeVNlbGVjdG9yQWxsKCJkaXYuc2VjdGlvbltjbGFzcyo9J2xldmVsJ10gPiA6Zmlyc3QtY2hpbGQiKTsKICB2YXIgaSwgaCwgYTsKICBmb3IgKGkgPSAwOyBpIDwgaHMubGVuZ3RoOyBpKyspIHsKICAgIGggPSBoc1tpXTsKICAgIGlmICghL15oWzEtNl0kL2kudGVzdChoLnRhZ05hbWUpKSBjb250aW51ZTsgIC8vIGl0IHNob3VsZCBiZSBhIGhlYWRlciBoMS1oNgogICAgYSA9IGguYXR0cmlidXRlczsKICAgIHdoaWxlIChhLmxlbmd0aCA+IDApIGgucmVtb3ZlQXR0cmlidXRlKGFbMF0ubmFtZSk7CiAgfQp9KTsK"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>


<style type="text/css">
  code {
    white-space: pre;
  }
  .sourceCode {
    overflow: visible;
  }
</style>
<style type="text/css" data-origin="pandoc">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>

<style type="text/css">
  p.abstract{
    text-align: center;
    font-weight: bold;
  }
  div.abstract{
    margin: auto;
    width: 90%;
  }
</style>


<style type="text/css">
/* for pandoc --citeproc since 2.11 */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}
</style>

<link rel="stylesheet" href="data:text/css,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" type="text/css" />




</head>

<body>




<h1 class="title toc-ignore">The R package singcar: Comparing Single Cases to Small Samples</h1>
<h4 class="author">Jonathan Ö. Rittmo</h4>
<address class="author_afil">
University of Edinburgh<br><a class="author_email" href="mailto:#"><a href="mailto:j.rittmo@gmail.com" class="email">j.rittmo@gmail.com</a></a>
</address>
<h4 class="author">Robert D. McIntosh</h4>
<address class="author_afil">
University of Edinburgh<br><a class="author_email" href="mailto:#"><a href="mailto:r.d.mcintosh@ed.ac.uk" class="email">r.d.mcintosh@ed.ac.uk</a></a>
</address>
<div class="abstract">
<p class="abstract">Abstract</p>
<p>Comparison of single cases to populations estimated from a sample has many potential applications. Historically, one major application is in the field of neuropsychology, where single-case statistics may be used to infer whether an individual has suffered a significant cognitive deficit as the consequence of a brain lesion. One may wish to estimate whether that individual has abnormally low performance on some cognitive ability, or if one cognitive ability is abnormally discrepant with respect to another cognitive ability. Several statistical methods have been developed to test for abnormality on a single variate and abnormality of the difference between two variates when a single case is compared to a sample, without losing control of the Type I error rate. This paper describes some of the main methods and presents a package in which they are implemented.</p>
</div>



<div id="introduction" class="section level1" number="1">
<h1><span class="header-section-number">1</span> Introduction</h1>
<p>There are many reasons why researchers and clinicians might want to look at
single cases instead of at the average of some group. In certain fields, such as
neuropsychology, this need arises because the pattern of naturally-occurring
brain damage will be unique in each individual case. From a theoretical
perspective, this means that a single patient might be the only available source
of data for a given phenomenon. From a practical, clinical perspective,
diagnosis and description of the pattern of cognitive impairment is done at the
individual level. Individual brain-damaged patients are thus often compared to
the healthy population to assess changes in cognitive functioning. If we want to
assess the patient score on some variate Y, for which we do not know the
population parameters, these must be estimated from a sample. Thus, the
single-case of interest is compared to a control sample. There are many other
areas where the application of such methods could also be useful: for example
studies of uncommon human expertise, targeted quality checks in industries with
limited production output, or animal studies where rearing a large experimental
group might be infeasible.</p>
<p>As it represents the canonical field for the application of these methods, the
nomenclature of neuropsychology will here be adopted. An abnormally low score on
a single variate will be referred to as a <em>deficit</em>, an important concept
for clinical and basic neuropsychology alike. For the latter area another
concept is also considered to be of cardinal importance: the ability to test for
<em>dissociation</em>, which is taken to provide evidence for some degree of
functional independence between two cognitive abilities. By charting
dissociations, a cognitive architecture of the mind can be theorized
<span class="citation">(<a href="#ref-shalliceNeuropsychologyMentalStructure1988" role="doc-biblioref">Shallice 1988</a>)</span>.</p>
<p>During the last 20 years methods have been developed to estimate and test for
both deficits and dissociations in the single case, while controlling the Type I
error rate, mainly by John Crawford and Paul Garthwaite
<span class="citation">(e.g., <a href="#ref-crawfordComparingIndividualTest1998" role="doc-biblioref">Crawford and Howell 1998</a>; <a href="#ref-crawfordComparingSingleCase2011" role="doc-biblioref">Crawford, Garthwaite, and Ryan 2011</a>; <a href="#ref-crawfordComparisonSingleCase2007" role="doc-biblioref">Crawford and Garthwaite 2007</a>, <a href="#ref-crawfordInvestigationSingleCase2002" role="doc-biblioref">2002</a>, <a href="#ref-crawfordTestingSuspectedImpairments2005" role="doc-biblioref">2005</a>)</span>.
They are available as standalone computer programs, only taking summary data as
input, at <a href="https://homepages.abdn.ac.uk/j.crawford/pages/dept/psychom.htm" class="uri">https://homepages.abdn.ac.uk/j.crawford/pages/dept/psychom.htm</a>.
But the majority of these methods have not yet been implemented in any standard
statistical environment. By doing so in the package <code>singcar</code> for the <code>R</code>
environment <span class="citation">(<a href="#ref-rcoreteamLanguageEnvironmentStatistical2020" role="doc-biblioref">R Core Team 2020</a>)</span>, our aim
is to encourage and simplify their usage. Further, limiting Type II errors has
not received as much attention as limiting Type I errors in single-case
methodology <span class="citation">(<a href="#ref-mcintoshPowerCalculationsSinglecase2020" role="doc-biblioref">McIntosh and Rittmo 2020</a>)</span>. By including novel tools
for power calculations, our hope is to increase awareness of the inherently low
power in this field as well as to aid in the planning and design of experiments.</p>
<p>The <code>R</code> package <code>singcar</code> contains seven functions to estimate a case’s
abnormality compared to a normal population estimated from a small sample, three of them
with regards to a single variate and four with regards to the discrepancy between two variates.
Both frequentist and Bayesian methods are provided, all developed originally by
Crawford and colleagues <span class="citation">(<a href="#ref-crawfordComparingIndividualTest1998" role="doc-biblioref">Crawford and Howell 1998</a>; <a href="#ref-crawfordComparingSingleCase2011" role="doc-biblioref">Crawford, Garthwaite, and Ryan 2011</a>; <a href="#ref-crawfordComparisonSingleCase2007" role="doc-biblioref">Crawford and Garthwaite 2007</a>, <a href="#ref-crawfordInvestigationSingleCase2002" role="doc-biblioref">2002</a>, <a href="#ref-crawfordTestingSuspectedImpairments2005" role="doc-biblioref">2005</a>)</span>.
Of special note for psychological research are the
methods allowing the inclusion of covariates <span class="citation">(<a href="#ref-crawfordComparingSingleCase2011" role="doc-biblioref">Crawford, Garthwaite, and Ryan 2011</a>)</span>
using Bayesian regression techniques (Section <a href="#cov">2.3.3</a>). These methods make matching the control
sample to the case less cumbersome.</p>
<p>In Section <a href="#section2">2</a> the implemented methods are described in detail and in
Section <a href="#section3">3</a> the package is described and usage exemplified with a
dataset from a recent neuropsychological single case study.</p>
</div>
<div id="section2" class="section level1" number="2">
<h1><span class="header-section-number">2</span> Comparing a single case to small samples</h1>
<div id="background" class="section level2" number="2.1">
<h2><span class="header-section-number">2.1</span> Background</h2>
<p>In the neuropsychological application of the methods to be presented,
the variates of interest will be scores obtained by participants on tasks
assessing relevant cognitive functions. The variates will
thus often be referred to as task scores. Historically, it was not uncommon for
researchers to compare single cases against a control
population estimated from a sample by evaluating the case score as a
<span class="math inline">\(Z\)</span> score from the estimated distribution. The <span class="math inline">\(p\)</span> value associated with this
<span class="math inline">\(Z\)</span> score would then be treated as an estimate of the case’s abnormality. A
similar logic was sometimes applied for estimating the abnormality of the
discrepancy between two tasks, using a method developed by <span class="citation"><a href="#ref-payneStatisticsInvestigationIndividual1957" role="doc-biblioref">Payne and Jones</a> (<a href="#ref-payneStatisticsInvestigationIndividual1957" role="doc-biblioref">1957</a>)</span>:
researchers calculated a <span class="math inline">\(Z\)</span> score based on the case’s difference
between two standardised variates divided by the standard deviation of the
difference.</p>
<p>The <span class="math inline">\(Z\)</span> score approach is of course problematic because it treats parameter estimations from
a restricted control sample as if they were population parameters. This could
be appropriate with very large samples, but
control samples in neuropsychology are often small (sometimes &lt; 10), and it is
well known that the sampling distribution of the sample variance is right skewed
for small sample sizes. Hence, underestimation of variance would be more
probable than overestimation, inflating obtained <span class="math inline">\(Z\)</span> scores and thus
Type I errors if the Z scores were used for hypothesis testing <span class="citation">(<a href="#ref-crawfordComparingIndividualTest1998" role="doc-biblioref">Crawford and Howell 1998</a>)</span>.</p>
<p>The following sections describe methods that have been devised to
allow for the evaluation of the abnormality of a case against a restricted
control sample, whilst retaining appropriate control over the Type I error rate.
These methods include frequentist approaches (Section <a href="#sec22">2.2</a>) and Bayesian
approaches (Section <a href="#sec23">2.3</a>).</p>
</div>
<div id="sec22" class="section level2" number="2.2">
<h2><span class="header-section-number">2.2</span> Frequentist approaches</h2>
<p>An appropriate method for comparing a single observation to the mean of a
sample was proposed within the biological sciences by <span class="citation"><a href="#ref-sokalBiometryPrinciplesPractice1981" role="doc-biblioref">Sokal and Rohlf</a> (<a href="#ref-sokalBiometryPrinciplesPractice1981" role="doc-biblioref">1981</a>)</span> (p.
227). It was popularized within neuropsychology by <span class="citation"><a href="#ref-crawfordComparingIndividualTest1998" role="doc-biblioref">Crawford and Howell</a> (<a href="#ref-crawfordComparingIndividualTest1998" role="doc-biblioref">1998</a>)</span>,
where its common application was as a (one-tailed) test of deficit (TD) to
determine whether the score of a single case with brain damage was abnormally
low (assuming that a low score indicates poorer performance) with respect to the
mean score of a control sample. The <span class="math inline">\(t\)</span> distribution is used to account for
the underestimation of the sample variance. The basic approach is a modified two
samples <span class="math inline">\(t\)</span> test where the case simply is treated as a sample of size 1. The
degrees of freedom for this distribution is <span class="math inline">\(n + 1 - 2 = n - 1\)</span>.</p>
<p><span class="math display" id="eq:TD">\[\begin{equation}
t_{n-1} = \frac{y^* - \overline{y}}{s \sqrt{\frac{n + 1}{n}}}
\tag{2.1}
\label{eq:TD}
\end{equation}\]</span></p>
<p>Where <span class="math inline">\(y^*\)</span> is the case score, <span class="math inline">\(\overline{y}, \ s\)</span> the sample mean and sample
standard deviation respectively and <span class="math inline">\(n\)</span> the size of the control sample. This
method does not allow estimation of a notional patient population. However,
since the question posed when using this test is about
the probability of the case being part of the control population, the potential alternative
affinity of the case is of no concern <span class="citation">(<a href="#ref-crawfordComparingIndividualTest1998" role="doc-biblioref">Crawford and Howell 1998</a>)</span>. This
test of deficit provides transparent control of the Type I error rate <span class="citation"><a href="#ref-crawfordSinglecaseResearchNeuropsychology2012" role="doc-biblioref">Crawford and Garthwaite</a> (<a href="#ref-crawfordSinglecaseResearchNeuropsychology2012" role="doc-biblioref">2012</a>)</span>.
Moreover, the <span class="math inline">\(p\)</span> value obtained constitutes an unbiased point estimate of the
abnormality of the case, as demonstrated by <span class="citation"><a href="#ref-crawfordMethodsTestingDeficit2006" role="doc-biblioref">Crawford and Garthwaite</a> (<a href="#ref-crawfordMethodsTestingDeficit2006" role="doc-biblioref">2006</a>)</span>. The
simple proof for this is given below.</p>
<p>The proportion of controls that would score lower on a random variable <span class="math inline">\(Y\)</span> than
the case <span class="math inline">\(y^*\)</span> is
<span class="math display">\[
\mathbb{P}[Y&lt; y^*]
\]</span>
Subtracting <span class="math inline">\(\overline{y}\)</span> from both sides of the inequality
and dividing by <span class="math inline">\(s \sqrt{\frac{n + 1}{n}}\)</span>
<span class="math display">\[
\mathbb{P}[Y&lt; y^*] =\mathbb{P}\left[\frac{Y-\overline{y}}{s \sqrt{\frac{n + 1}{n}}} &lt; \frac{y^* - \overline{y}}{s \sqrt{\frac{n + 1}{n}}}\right]
\]</span>
The quantity to the left of the inequality, i.e., <span class="math inline">\(\frac{y-\overline{y}}{s \sqrt{\frac{n + 1}{n}}}\)</span>
is <span class="math inline">\(t\)</span> distributed with <span class="math inline">\(n-1\)</span> degrees of freedom. Hence,
<span class="math display">\[
\mathbb{P}[Y&lt; y^*] =\mathbb{P}\left[t_{n-1} &lt; \frac{y^* - \overline{y}}{s \sqrt{\frac{n + 1}{n}}}\right]
\]</span>
The quantity to the right of the inequality is the test statistic from
Equation <a href="#eq:TD">(2.1)</a>, hence <span class="math inline">\(\mathbb{P}[y&lt; y^*]\)</span> is the same as the <span class="math inline">\(p\)</span> value obtained
from the test of deficit. This fact also makes the construction of confidence
intervals of this abnormality possible.</p>
<p><span class="citation"><a href="#ref-crawfordPointIntervalEstimates2010" role="doc-biblioref">Crawford, Garthwaite, and Porter</a> (<a href="#ref-crawfordPointIntervalEstimates2010" role="doc-biblioref">2010</a>)</span> pointed out that, although the <span class="math inline">\(Z\)</span> score
is not appropriate for estimating the abnormality of a case when the control
sample is small, it does provide a standardised effect size measure of
abnormality, similar to Cohen’s d <span class="citation">(<a href="#ref-cohenStatisticalPowerAnalysis1988" role="doc-biblioref">Cohen 1988</a>)</span>. Insensitivity to sample size is
indeed a requirement for an effect size index and the proposed quantity was:
<span class="math display" id="eq:zcc">\[\begin{equation}
Z_{CC} = \frac{y^* - \overline{y}}{s}
\tag{2.2}
\label{eq:zcc}
\end{equation}\]</span>
This is simply a <span class="math inline">\(Z\)</span> score calculated from sample estimates. The
subscript (CC) indicates that it relates to a “case-controls” comparison. The
construction of confidence intervals for the point estimate of abnormality using
the <span class="math inline">\(Z_{CC}\)</span> index of effect size was described by <span class="citation"><a href="#ref-crawfordInvestigationSingleCase2002" role="doc-biblioref">Crawford and Garthwaite</a> (<a href="#ref-crawfordInvestigationSingleCase2002" role="doc-biblioref">2002</a>)</span>.</p>
<p>Put <span class="math inline">\(p\)</span> as the percentage of the population that would fall below a
case score, then the <span class="math inline">\(1-\frac{\alpha}{2}\)</span> confidence interval for <span class="math inline">\(p\)</span> is
constructed as follows: Let <span class="math inline">\(Z_{CC} = \frac{y^*-\overline{y}}{s}\)</span> and <span class="math inline">\(y^* \neq \overline{y}\)</span>
then <span class="math inline">\(Z_{CC}\)</span> comes from a non-central <span class="math inline">\(t\)</span> distribution on <span class="math inline">\(n-1\)</span>
degrees of freedom. By deploying a search algorithm we find the value <span class="math inline">\(\delta_U\)</span>
for the non-centrality parameter (NCP) of a non-central <span class="math inline">\(t\)</span> distribution on <span class="math inline">\(n-1\)</span>
degrees of freedom such that the <span class="math inline">\(100\frac{\alpha}{2}\)</span> percentile equates
<span class="math inline">\(Z_{CC}\sqrt{n}\)</span> and similarly we find the NCP <span class="math inline">\(\delta_L\)</span> of a non-central
<span class="math inline">\(t\)</span> distribution such that its <span class="math inline">\(100(1-\frac{\alpha}{2})\)</span> percentile equates
<span class="math inline">\(Z_{CC}\sqrt{n}\)</span>. The upper and lower boundaries for <span class="math inline">\(Z_{CC}\)</span> are then given by:
<span class="math display">\[
Z_{CC_U} = \frac{\delta_U}{n}, \ \ Z_{CC_L} = \frac{\delta_L}{n}
\]</span>
and the boundaries for <span class="math inline">\(p\)</span> by:
<span class="math display">\[
p_U = \Phi\left(\frac{\delta_U}{n}\right), \ p_L = \Phi\left(\frac{\delta_L}{n}\right)
\]</span>
Where <span class="math inline">\(\Phi\)</span> is the CDF of the standard normal distribution. Note that the above
equation is appropriate when the case score falls on the left side of the
distribution. If it were to fall on the right side, then the upper and lower
boundaries would be given by:
<span class="math display">\[
p_U = 1 - \Phi\left(\frac{\delta_L}{n}\right), \ p_L = 1 - \Phi\left(\frac{\delta_U}{n}\right)
\]</span></p>
<p>As has been shown, estimating abnormality on a single variate is a simple
matter. For estimating abnormality of discrepancy, when the normally distributed
variates <span class="math inline">\(Y_1\)</span> and <span class="math inline">\(Y_2\)</span> can be compared without standardisation, the approach
is equally simple and in fact identical to the test of deficit, Equation <a href="#eq:TD">(2.1)</a>,
except that the statistic is based on difference scores, taking the correlation
between the variates into account (<span class="math inline">\(\rho_{12}\)</span>).
<span class="math display" id="eq:UDT">\[\begin{equation}
t_{n-1} = \frac{(y^*_1 - \overline{y}_1) - (y^* _2 - \overline{y}_2) }{ \sqrt{(s^2_1 +s^2_2 -2s_1 s_2 \rho_{12})(\frac{n+1}{n})}}
\tag{2.3}
\label{eq:UDT}
\end{equation}\]</span>
Construction of confidence intervals for abnormality estimates based on this
unstandardised difference test (UDT) is done in an analogous way to that of the
confidence intervals of the TD <span class="citation">(<a href="#ref-crawfordTestingSuspectedImpairments2005" role="doc-biblioref">Crawford and Garthwaite 2005</a>)</span>.
However, the test is somewhat limited in its usefulness, because it is only
applicable if the two variates are measured on equivalent scales. Far more
common, at least in neuropsychology, is the need to assess discrepancies between
differently-scaled variates, which require standardisation to be comparable.</p>
<p>By standardising the variates (not taking sample size into account)
we get an effect size measure similar to <span class="math inline">\(Z_{CC}\)</span>,
Equation <a href="#eq:zcc">(2.2)</a> <span class="citation">(<a href="#ref-crawfordPointIntervalEstimates2010" role="doc-biblioref">Crawford, Garthwaite, and Porter 2010</a>)</span>:
<span class="math display" id="eq:PJ">\[\begin{equation}
Z_{DCC}  = \frac{z^*_1 - z^*_2}{\sqrt{2-2\rho_{12}}}
\tag{2.4}
\label{eq:PJ}
\end{equation}\]</span>
Where <span class="math inline">\(z_1^*\)</span> and <span class="math inline">\(z_2^*\)</span> are the standardised case scores on some task A
and some task B and the subscript (DCC) indicates “discrepancy-case-controls.”
This quantity was proposed by <span class="citation"><a href="#ref-payneStatisticsInvestigationIndividual1957" role="doc-biblioref">Payne and Jones</a> (<a href="#ref-payneStatisticsInvestigationIndividual1957" role="doc-biblioref">1957</a>)</span>
as a significance test for discrepancies, but of course it is not appropriate
for such a purpose if small samples are used: we cannot use the <span class="math inline">\(Z\)</span>
distribution for estimating the abnormality of the discrepancy for the same
reason we cannot use <span class="math inline">\(Z_{CC}\)</span> to test for a deficit.
<!-- But also because we cannot use  \(Z\) scores to represent the case's scores -->
<!-- on each variate since the size of these will be inflated as well. --></p>
<p>When the case scores on variates <span class="math inline">\(Y_1\)</span> and <span class="math inline">\(Y_2\)</span> are estimated from small
samples and they need to be standardised, it means that instead of estimating
the discrepancy between two normally distributed variates we need to estimate
the discrepancy between two <span class="math inline">\(t\)</span> distributed variates.
Because linear combinations of correlated <span class="math inline">\(t\)</span> distributed random variates are not
themselves <span class="math inline">\(t\)</span> distributed this problem is non-trivial. The distribution of such
difference scores was examined by <span class="citation"><a href="#ref-garthwaiteDistributionDifferenceTwo2004" role="doc-biblioref">Garthwaite and Crawford</a> (<a href="#ref-garthwaiteDistributionDifferenceTwo2004" role="doc-biblioref">2004</a>)</span>. They used
asymptotic expansion to find functions of the sample correlation that, if used
as a denominator to the difference between the variates, would yield an
asymptotically <span class="math inline">\(t\)</span> distributed quantity. They found:</p>
<p><span class="math display">\[\begin{equation}
\psi=\frac{\frac{(y^*_1-\overline{y}_1)}{s_{1}}-\frac{(y^*_2-\overline{y}_2)}{s_{2}}}{
\sqrt{
(\frac{n+1}{n})
\left( (2-2 \rho)+
\frac{2(1-\rho^{2})}{n-1}+
\frac{(5+c^{2})(1-\rho^{2})}{2(n-1)^{2}}+
\frac{\rho(1+c^{2})(1-\rho^{2})}{2(n-1)^{2}}\right)
}}
\end{equation}\]</span></p>
<p>Where <span class="math inline">\(\rho\)</span> is the sample correlation between the tasks and <span class="math inline">\(c\)</span> the critical
two-tailed <span class="math inline">\(t\)</span> value with <span class="math inline">\(n-1\)</span> degrees of freedom. <span class="citation"><a href="#ref-garthwaiteDistributionDifferenceTwo2004" role="doc-biblioref">Garthwaite and Crawford</a> (<a href="#ref-garthwaiteDistributionDifferenceTwo2004" role="doc-biblioref">2004</a>)</span>
demonstrated that <span class="math inline">\(\mathbb{P}[ \psi &gt; c] \approx \mathbb{P}[t &gt;c]\)</span>. To obtain a
precise probability for <span class="math inline">\(\psi\)</span>, one solves for <span class="math inline">\(\psi = c\)</span>, which gives a quantity
not dependent on a pre-specified critical value.
<span class="math inline">\(\psi = c\)</span> is a quadratic equation in <span class="math inline">\(c^2\)</span>, choosing the positive root of which
yields:</p>
<p><span class="math display" id="eq:RSDT">\[\begin{align}
\begin{split}
c &amp; = \sqrt{\frac{ -b + \sqrt{b^2 - 4ad}}{2a}}, \  \text{where} \\
a &amp; = (1+r)(1-r^2), \\
b &amp; =  (1-r)[4(n-1)^2+4(1+r)(n-1)+(1+r)(5+r)], \\
d &amp; =  - 2\left[\frac{y^*_{1} - \overline{y}_1}{s_1}-\frac{y^*_2 -\overline{y}_2}{s_2}\right]^2\left(\frac{n(n-1)^2}{n+1}\right)
\end{split}
\tag{2.5}
\label{eq:RSDT}
\end{align}\]</span></p>
<p>Where <span class="math inline">\(p = \mathbb{P}[t_{n-1}&gt;c]\)</span> is the estimate of abnormality, and is used for
significance testing. It should be noted that because <span class="math inline">\(c\)</span> is quadratic and we
choose the positive root, the resultant statistic cannot be negative.
If it is required that the test statistic expresses the direction of a negative
effect the correct sign must be imposed.</p>
<p>The quantity in Equation <a href="#eq:RSDT">(2.5)</a> is referred to as the “revised
standardised difference test”
. The name stems from it
being preceded by a test similar to that of the unstandardised difference test
(Equation <a href="#eq:UDT">(2.3)</a>) but with standardised normal variates, developed by
<span class="citation"><a href="#ref-crawfordPayneJonesRevisited1998" role="doc-biblioref">Crawford, Howell, and Garthwaite</a> (<a href="#ref-crawfordPayneJonesRevisited1998" role="doc-biblioref">1998</a>)</span>.
<span class="citation"><a href="#ref-crawfordTestingSuspectedImpairments2005" role="doc-biblioref">Crawford and Garthwaite</a> (<a href="#ref-crawfordTestingSuspectedImpairments2005" role="doc-biblioref">2005</a>)</span> show with Monte Carlo
simulations that the RSDT is superior in controlling Type I errors compared to
their earlier <span class="math inline">\(t\)</span> test and the <span class="math inline">\(Z\)</span> score method of
<span class="citation"><a href="#ref-payneStatisticsInvestigationIndividual1957" role="doc-biblioref">Payne and Jones</a> (<a href="#ref-payneStatisticsInvestigationIndividual1957" role="doc-biblioref">1957</a>)</span>.</p>
<p>Even for very small sample sizes of <span class="math inline">\(n=5\)</span>, RSDT was shown to barely exceed the
specified 5% error rate. However, if a case lacks a true discrepancy
between the variates but exhibits extreme scores on both of them (in the same direction), the error rate
of the RSDT increases steeply. <span class="citation"><a href="#ref-crawfordComparisonSingleCase2007" role="doc-biblioref">Crawford and Garthwaite</a> (<a href="#ref-crawfordComparisonSingleCase2007" role="doc-biblioref">2007</a>)</span>
showed that the RSDT starts to lose control of the
error for task scores being more extreme than two standard deviations away from
the mean on both variates, without them exhibiting a discrepancy. For task
scores at 8 standard deviations from the mean, the Type I error rate of the RSDT
was inflated to nearly 35%.</p>
<p>Another major drawback of the RSDT is that it has proved difficult to construct
confidence limits on the point estimate of abnormality due to <span class="math inline">\(\psi\)</span> only being
approximately <span class="math inline">\(t\)</span> distributed. To remedy this and to be able to provide an exact
rather than just approximate estimate of abnormality Crawford and colleagues started
looking into Bayesian methodology.</p>
</div>
<div id="sec23" class="section level2" number="2.3">
<h2><span class="header-section-number">2.3</span> Bayesian approaches</h2>
<p>In the frequentist framework, parameters are treated as fixed attributes of a
population and their estimations are thought to converge to the true value
across a series of trials. In the Bayesian framework, by contrast, parameters
are treated as random variables with associated probability distributions. To
estimate a parameter distribution, we can use any prior knowledge of that
parameter to assign probabilities to possible values of the parameter, forming
what is known as a prior distribution, or simply a prior. If no prior
information is available we may want to use a non-informative prior, the most
simple of which would assign equal probabilities to all possible parameter
values. The prior is updated when new information is obtained to form what is
called a posterior distribution. The posterior probability of a hypothesis
(i.e., a specified value of the parameter) is calculated by using Bayes theorem.
If we disregard the marginal probability of the data in Bayes theorem it can be
rewritten as:
<span class="math display">\[\begin{equation*}
posterior \ \propto \ likelihood \times prior
\end{equation*}\]</span></p>
<p>What this is saying is that the posterior density of a hypothesis is
proportional (<span class="math inline">\(\propto\)</span>) to the likelihood of the data under that hypothesis times the
prior probability of the hypothesis.</p>
<p>In many cases it is not feasible to calculate the posterior analytically and
instead Monte Carlo methods are often used. These methods are
mathematical algorithms that solve numerical problems by repeated sampling from
distributions. The algorithms used differ depending on the problem at hand, but
in general they are all building on rules of drawing random numbers based on the
likelihood and the prior, and observing the distribution formed after a large
number of iterations. The peak of such a distribution is often taken as an
estimation of the parameter of interest and when using non-informative priors
this often also corresponds to the maximum likelihood estimate. Hence, using a
non-informative prior often yields estimations with frequentist properties, a
feature that is useful if hypothesis testing is desired.</p>
<p>This was a requirement when <span class="citation"><a href="#ref-crawfordComparisonSingleCase2007" role="doc-biblioref">Crawford and Garthwaite</a> (<a href="#ref-crawfordComparisonSingleCase2007" role="doc-biblioref">2007</a>)</span> and
<span class="citation"><a href="#ref-crawfordComparingSingleCase2011" role="doc-biblioref">Crawford, Garthwaite, and Ryan</a> (<a href="#ref-crawfordComparingSingleCase2011" role="doc-biblioref">2011</a>)</span> developed Bayesian versions of the tests
described in Section <a href="#sec22">2.2</a>, now implemented in <code>singcar</code>. The
following sections describe the procedural details of these methods which are
all based on Monte Carlo simulations. The steps presented closely follow those
outlined in the original papers with just a few slight changes of notation.</p>
<div id="BTD" class="section level3" number="2.3.1">
<h3><span class="header-section-number">2.3.1</span> The Bayesian test of deficit</h3>
<p>The Bayesian test of deficit (BTD) allows us to obtain an estimate of <span class="math inline">\(p\)</span> (and accompanying credible
intervals), which is the proportion of controls that would obtain a value more
extreme than the case on the variate of interest.</p>
<p>Assume a sample of <span class="math inline">\(n\)</span> controls on which we measure
some value <span class="math inline">\(y\)</span> that is normally distributed with unknown mean <span class="math inline">\(\mu\)</span> and unknown
variance <span class="math inline">\(\sigma^2\)</span>. Let <span class="math inline">\(\overline{y}\)</span> and <span class="math inline">\(s^2\)</span> denote the sample mean and
sample variance respectively and <span class="math inline">\(y^*\)</span> the case score.
Because <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span> are unknown, the prior distribution of <span class="math inline">\(\mu\)</span> is
conditioned on the prior distribution of <span class="math inline">\(\sigma^2\)</span>.
A non-informative prior <span class="math inline">\(\mu | \sigma^2 \sim \mathcal{N}(0, \ \infty)\)</span> is
assumed. For the posterior we have that
the marginal distribution of <span class="math inline">\(\frac{(n-1)s^2}{\sigma^2} \sim \chi^2_{n-1}\)</span> and
the posterior distribution for
<span class="math inline">\(\mu|\sigma^2 \sim \mathcal{N}(\overline{y}, \sigma^2/n)\)</span>, see e.g., <span class="citation"><a href="#ref-gelmanBayesianDataAnalysis2013" role="doc-biblioref">Gelman et al.</a> (<a href="#ref-gelmanBayesianDataAnalysis2013" role="doc-biblioref">2013</a>)</span> (p. 45 and 65).
To estimate <span class="math inline">\(p\)</span>, the following steps are iterated:</p>
<ol style="list-style-type: decimal">
<li><p>Let <span class="math inline">\(\psi\)</span> be a random draw from a <span class="math inline">\(\chi^2\)</span>-distribution on <span class="math inline">\(n-1 \ df\)</span>.
Then let <span class="math inline">\(\hat{\sigma}^2_{(i)} = \frac{(n-1)s^2}{\psi}\)</span> be the estimation of
<span class="math inline">\(\sigma^2\)</span> for this iteration, hence the subscript <span class="math inline">\((i)\)</span>.</p></li>
<li><p>Let <span class="math inline">\(z\)</span> be a random draw from a standard normal distribution.
Then let <span class="math inline">\(\hat{\mu}_{(i)}=\overline{y}+z\sqrt{(\hat{\sigma}_{(i)}^2/n)}\)</span> be
the estimate of <span class="math inline">\(\mu\)</span> for this iteration.</p></li>
<li><p>With estimates of <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>, <span class="math inline">\(p\)</span> is calculated conditional
on these estimates being the “correct” <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span>. Let
<span class="math inline">\(z^*_{(i)}= \frac{y^* - \hat{\mu}_{(i)}}{\sqrt{\hat{\sigma}_{(i)}^2}}\)</span> be the standardised
case score then <span class="math inline">\(\hat{p}_{(i)} =\Phi\left(z^*_{(i)}\right)\)</span> or <span class="math inline">\(\hat{p}_{(i)} = 1-\Phi\left(z^*_{(i)}\right)\)</span>
depending on alternative hypothesis, is the estimate of <span class="math inline">\(p\)</span> for this
iteration. That is the probability of drawing a
value more extreme than <span class="math inline">\(z^*_{(i)}\)</span> from a standard normal distribution.</p></li>
</ol>
<p>Repeating these steps a large number of times will yield a distribution
of <span class="math inline">\(\hat{p}\)</span>, the mean of which is taken as the point estimate of <span class="math inline">\(p\)</span> and used
for hypothesis testing. Multiplied by 100 it gives a point estimate of the percentage
of the control population expected to exhibit a more extreme score than the case. If repeated
e.g., 1000 times, the 25th smallest and 25th largest <span class="math inline">\(\hat{p}_{(i)}\)</span> would give the lower and
upper boundaries of the 95% credible interval for <span class="math inline">\(p\)</span>. Similarly,
the 25th smallest and 25th largest values of <span class="math inline">\(z^*_{(i)}\)</span> would give the lower and
upper boundaries of the 95% credible interval for <span class="math inline">\(Z_{CC}\)</span> the point
estimate of which is that of Equation <a href="#eq:zcc">(2.2)</a>. <span class="citation"><a href="#ref-crawfordComparisonSingleCase2007" role="doc-biblioref">Crawford and Garthwaite</a> (<a href="#ref-crawfordComparisonSingleCase2007" role="doc-biblioref">2007</a>)</span>
show that this method yields converging results to that of the frequentist test of deficit, Equation <a href="#eq:TD">(2.1)</a>.</p>
</div>
<div id="BSDT" class="section level3" number="2.3.2">
<h3><span class="header-section-number">2.3.2</span> The Bayesian standardised difference test</h3>
<p>The Bayesian standardised difference test (BSDT) follow a similar procedure to
that of BTD. However, we now assume a sample of <span class="math inline">\(n\)</span> controls from which we
obtain values on the variates <span class="math inline">\(Y_1\)</span> and <span class="math inline">\(Y_2\)</span> following a bivariate normal
distribution and representing task A and task B. Let <span class="math inline">\(\overline{y}_1\)</span> and
<span class="math inline">\(\overline{y}_2\)</span> denote the sample means and
<span class="math display">\[\begin{equation*}
\pmb{A}=\begin{bmatrix}
s^2_{1} &amp; s_{12} \\
s_{12} &amp; s^2_{2} \end{bmatrix}
\end{equation*}\]</span>
the sample variance-covariance matrix, where <span class="math inline">\(s_{12}\)</span> is the sample covariance,
then <span class="math inline">\(\pmb{S} =\pmb{A}(n-1)\)</span> is the sums of squares and cross products (SSCP) matrix. It
is assumed that the observations come from a bivariate normal distribution with
unknown mean <span class="math inline">\(\pmb{\mu}\)</span> and unknown variance <span class="math inline">\(\Sigma\)</span>:</p>
<p><span class="math display">\[\begin{equation*}
\pmb{\mu} = \begin{pmatrix}
\mu_1 \\
\mu_2 \end{pmatrix} \ \text{and} \ \Sigma=\begin{bmatrix}
\sigma^2_{1} &amp; \sigma_{12} \\
\sigma_{12} &amp; \sigma^2_{2} \end{bmatrix}
\end{equation*}\]</span></p>
<p>Let the case scores be denoted <span class="math inline">\(y_1^*\)</span> and <span class="math inline">\(y_2^*\)</span>. Just as for the frequentist
dissociation tests we want to estimate the proportion <span class="math inline">\(p\)</span> of the control
population that would exhibit a greater difference <span class="math inline">\(Y_1-Y_2\)</span> than the case’s
<span class="math inline">\(y_1^*-y_2^*\)</span>.</p>
<p>The multivariate generalization of the <span class="math inline">\(\chi^2\)</span>-distribution is the Wishart
distribution. That is, a Wishart distribution of 1 dimension is a
<span class="math inline">\(\chi^2\)</span>-distribution on <span class="math inline">\(n\)</span> degrees of freedom. One can view the Wishart
distribution parameterised with <span class="math inline">\(n\)</span> degrees of freedom and some
variance-covariance matrix as being a distribution of SSCP-matrices related to
that variance-covariance matrix. Similarly, one can view the inverse Wishart
distribution parameterised with the same degrees of freedom and a SSCP-matrix as
being a distribution of variance-covariance matrices related to that
SSCP-matrix.</p>
<p>The non-informative prior for <span class="math inline">\(f(\pmb\mu, \Sigma^{-1})\)</span> chosen in
<span class="citation"><a href="#ref-crawfordComparisonSingleCase2007" role="doc-biblioref">Crawford and Garthwaite</a> (<a href="#ref-crawfordComparisonSingleCase2007" role="doc-biblioref">2007</a>)</span> was <span class="math inline">\(f(\pmb\mu, \Sigma^{-1}) \propto |\Sigma|\)</span> in favour of the perhaps more commonly used <span class="math inline">\(f(\pmb\mu, \Sigma^{-1}) \propto |\Sigma|^{(k+1)/2}\)</span> (<span class="math inline">\(k =\)</span> number of variates) because, for unstandardised differences, it was shown
to yield identical interval estimates to the frequentist UDT. The posterior
marginal distribution of <span class="math inline">\(\Sigma^{-1}\)</span> for this choice of prior is a Wishart
distribution with <span class="math inline">\(n\)</span> degrees of freedom and scale matrix <span class="math inline">\(\pmb{S}^{-1}\)</span>.
The conditional distribution of <span class="math inline">\(\pmb\mu|\Sigma\)</span> is then a multivariate normal
distribution with mean <span class="math inline">\([\overline{y}_1 \ \overline{y}_2]\)</span> and variance
<span class="math inline">\(\Sigma/n\)</span>, see e.g., <span class="citation"><a href="#ref-gelmanBayesianDataAnalysis2013" role="doc-biblioref">Gelman et al.</a> (<a href="#ref-gelmanBayesianDataAnalysis2013" role="doc-biblioref">2013</a>)</span> (p. 72-73).
<span class="citation"><a href="#ref-crawfordComparisonSingleCase2007" role="doc-biblioref">Crawford and Garthwaite</a> (<a href="#ref-crawfordComparisonSingleCase2007" role="doc-biblioref">2007</a>)</span> refer to this as the “standard theory”
prior.</p>
<p>Using the standard theory prior produces good frequentist properties for
<span class="math inline">\(\sigma_1\)</span> and <span class="math inline">\(\sigma_2\)</span>, but <span class="citation"><a href="#ref-bergerObjectivePriorsBivariate2008" role="doc-biblioref">Berger and Sun</a> (<a href="#ref-bergerObjectivePriorsBivariate2008" role="doc-biblioref">2008</a>)</span>
have shown that the convergence to frequentist estimates is less good for
<span class="math inline">\(\rho\)</span> and differences in means (<span class="math inline">\(\mu_1 - \mu_2\)</span>). Instead, they recommend
that <span class="math inline">\(f(\pmb\mu, \Sigma^{-1}) \propto \frac{1}{\sigma_1\sigma_2(1-\rho^2)}\)</span>
should be used as a general purpose prior for bivariate normal data.
To construct posteriors with this prior rejection sampling is used. Random
observations are drawn from an inverse Wishart on <span class="math inline">\(n-1\)</span>
degrees of freedom and only a subset of the draws are accepted.
<span class="citation"><a href="#ref-crawfordComparingSingleCase2011" role="doc-biblioref">Crawford, Garthwaite, and Ryan</a> (<a href="#ref-crawfordComparingSingleCase2011" role="doc-biblioref">2011</a>)</span> noticed however that this prior gave rise to too narrow
credible intervals and, with simulations, showed that if the sample size was
treated as <span class="math inline">\(n-1\)</span> for estimations of <span class="math inline">\(\Sigma\)</span>, so that the intervals were
somewhat conservative, the frequentist properties of their estimations were
improved. <span class="citation"><a href="#ref-crawfordComparingSingleCase2011" role="doc-biblioref">Crawford, Garthwaite, and Ryan</a> (<a href="#ref-crawfordComparingSingleCase2011" role="doc-biblioref">2011</a>)</span> recommend this and refer to it as the
“calibrated” prior. The procedure for sampling from the posterior using this
prior is given below:</p>
<ol style="list-style-type: decimal">
<li><p>Since the unbiased estimate of <span class="math inline">\(\Sigma\)</span> is <span class="math inline">\(\pmb{S}/(n-1)\)</span>,
we put <span class="math inline">\(\pmb{S}^*= (n-2)\pmb{S}/(n-1)\)</span> to retain this property
when reducing the sample size.</p></li>
<li><p>Generate an observation from an inverse Wishart distribution
on <span class="math inline">\(n-2\)</span> degrees of freedom and with scale matrix <span class="math inline">\(\pmb{S}^*\)</span>.
Denote this:
<span class="math display">\[
\hat{\Sigma} = \begin{bmatrix}
\hat{\sigma}^2_{1} &amp; \hat{\sigma}_{12} \\
\hat{\sigma}_{12} &amp; \hat{\sigma}^2_{2} \end{bmatrix}
\]</span>
and put
<span class="math display">\[
\hat{\rho}= \frac{\hat{\sigma}_{12}}{\sqrt{\hat{\sigma}^2_{1}\hat{\sigma}^2_{2}}}
\]</span></p></li>
<li><p>Generate a value <span class="math inline">\(u\)</span> from a uniform distribution such that <span class="math inline">\(u \sim U(0, 1)\)</span>.
If <span class="math inline">\(u^2 \leq 1-\hat{\rho}^2\)</span> we accept <span class="math inline">\(\hat\Sigma\)</span> as the estimation of
<span class="math inline">\(\Sigma\)</span> for this iteration and denote it
<span class="math display">\[\begin{equation*}
\hat{\Sigma}_{(i)}=\begin{bmatrix}
\hat{\sigma}^2_{1(i)} &amp; \hat{\sigma}_{12(i)} \\
\hat{\sigma}_{12(i)} &amp; \hat{\sigma}^2_{2(i)} \end{bmatrix}
\end{equation*}\]</span>
otherwise
we iterate the procedure until we have an accepted <span class="math inline">\(\hat{\Sigma}\)</span>.</p></li>
</ol>
<p>Bayesians might argue that good frequentist properties are not necessary when
conducting Bayesian analyses. If so, one can use the “standard theory” prior
by generating a random observation from an inverse Wishart distribution on <span class="math inline">\(n\)</span>
degrees of freedom and scale matrix <span class="math inline">\(\pmb{S}\)</span> and denote it
<span class="math inline">\(\hat{\Sigma}_{(i)}\)</span>. With an estimate of <span class="math inline">\(\Sigma\)</span> (regardless of the prior
chosen), follow the steps below to obtain an estimate of <span class="math inline">\(p\)</span>, that is the percentage
of the control population expected to show a more extreme score than the case.</p>
<ol style="list-style-type: decimal">
<li><p>Let <span class="math inline">\(z_{r1}\)</span> and <span class="math inline">\(z_{r2}\)</span> be two random draws from a standard normal distribution.
Perform Cholesky decomposition on <span class="math inline">\(\hat{\Sigma}_{(i)}\)</span>, that is finding the lower triangular matrix <span class="math inline">\(\pmb{T}\)</span>
such that <span class="math inline">\(\pmb{T}\pmb{T&#39;}=\hat{\Sigma}_{(i)}\)</span>. Then
<span class="math display">\[\begin{equation*}
\pmb{\hat{\mu}}_{(i)} = \begin{pmatrix}
\hat{\mu}_{1(i)} \\
\hat{\mu}_{2(i)} \end{pmatrix} = \begin{pmatrix}
\overline{y}_1 \\
\overline{y}_2 \end{pmatrix}+ \pmb{T} \begin{pmatrix}
z_{r1} \\
z_{r2} \end{pmatrix} / \sqrt{n}
\end{equation*}\]</span>
is the estimation of <span class="math inline">\(\pmb{\mu}\)</span> for this iteration.</p></li>
<li><p>With estimations of <span class="math inline">\(\pmb{\mu}\)</span> and <span class="math inline">\(\Sigma\)</span> we can calculate <span class="math inline">\(p\)</span>, given that
they are the the correct values of <span class="math inline">\(\pmb{\mu}\)</span> and <span class="math inline">\(\Sigma\)</span>. If an unstandardised
test is required put:
<span class="math display">\[\begin{equation*}
z_{(i)}^* = \frac{(y_1^* - \hat{\mu}_{1(i)}) - (y^*_2 - \hat{\mu}_{2(i)})}
{\sqrt{\hat{\sigma}^2_{1(i)}+\hat{\sigma}^2_{2(i)}-2\hat{\sigma}_{12(i)}}}
\end{equation*}\]</span>
If a standardised test is required, put:
<span class="math display">\[\begin{equation*}
z_{1(i)} = \frac{y_1^* - \hat{\mu}_{1(i)}}{\sqrt{\hat{\sigma}^2_{1(i)}}}, \ z_{2(i)} = \frac{y_2^* -
\hat{\mu}_{2(i)}}{\sqrt{\hat{\sigma}^2_{2(i)}}}, \ \hat{\rho}_{(i)} = \frac{\hat{\sigma}_{12(i)}}{\sqrt{\hat{\sigma}_{1(i)}\hat{\sigma}_{2(i)}}}
\end{equation*}\]</span>
and
<span class="math display">\[\begin{equation*}
z^*_{(i)} = \frac{z_{1(i)} - z_{2(i)}}{\sqrt{2-2\hat{\rho}_{(i)}}}
\end{equation*}\]</span></p></li>
<li><p>Let <span class="math inline">\(\hat{p}_{(i)}\)</span> be the tail area of a standard normal distribution
less or greater than <span class="math inline">\(z^*_{(i)}\)</span> (depending on alternative hypothesis).
<span class="math inline">\(\hat{p}_{(i)}\)</span> is then the estimate of <span class="math inline">\(p\)</span> for this iteration.</p></li>
</ol>
<p>Repeating these
steps a large number of times will yield a distribution of <span class="math inline">\(\hat{p}\)</span>, the
mean of which is taken as the point estimate of <span class="math inline">\(p\)</span> and used for hypothesis testing.
Multiplied by 100 it gives the point estimate of the percentage of controls expected to exhibit
a more extreme task difference than the case. If repeated e.g., 1000 times, the
25th smallest and 25th largest <span class="math inline">\(\hat{p}_i\)</span> is the lower and upper boundaries of the 95%
credible interval for <span class="math inline">\(p\)</span>. Similarly,
the 25th smallest and 25th largest values of <span class="math inline">\(z^*_{(i)}\)</span> gives the lower and
upper boundaries of the 95% credible interval for <span class="math inline">\(Z_{DCC}\)</span>, the point
estimate of which is that of Equation <a href="#eq:PJ">(2.4)</a>.</p>
</div>
<div id="cov" class="section level3" number="2.3.3">
<h3><span class="header-section-number">2.3.3</span> Bayesian tests allowing for covariates</h3>
<p><span class="citation"><a href="#ref-crawfordComparingSingleCase2011" role="doc-biblioref">Crawford, Garthwaite, and Ryan</a> (<a href="#ref-crawfordComparingSingleCase2011" role="doc-biblioref">2011</a>)</span> extended the previously described Bayesian tests by
using Bayesian regression techniques that allowed the case’s abnormality to be assessed
in the presence of covariates. These tests thus allow you to compare
the case’s score on the task of interest conditioned on the results of the
controls having the same score as the case on the covariate(s). If a case has 15
years of education, his/her score on the task would be compared to the controls
with equal length of education.</p>
<p>In addition to improving the precision of these tests, by accounting for
spurious noise, this also facilitates the collection of larger control samples,
because it reduces the need to very closely match control samples to a single
case. Moreover, it means that the same control sample may be used for the
evaluation of multiple single-cases, since the matching on relevant covariates
of interest can be achieved statistically. One degree of freedom is lost for
each covariate included, so as a rule of thumb they should be included only if
they have a sample correlation with the variate(s) of interest stronger than
<span class="math inline">\(0.3\)</span> <span class="citation">(<a href="#ref-crawfordComparingSingleCase2011" role="doc-biblioref">Crawford, Garthwaite, and Ryan 2011</a>)</span>. Of course, the control sample should also ideally
bracket the case on the covariates, in order to avoid extrapolating “out
of sample.” As for the earlier tests, the assumption of the variates of interest
are still that they follow a normal or bivariate normal distribution. However,
no assumptions are made about the distribution of the covariates.</p>
<p>Suppose we have data from a sample of size <span class="math inline">\(n\)</span>, with scores on <span class="math inline">\(m\)</span> covariates
and <span class="math inline">\(k = 1, 2\)</span> variates of interest, depending on whether we are testing for a
deficit or a discrepancy. We denote the covariates
<span class="math inline">\(\boldsymbol{X} = (X_1, \dots, X_m)\)</span>.</p>
<p>From these values we wish to estimate
<span class="math display">\[
\boldsymbol{B} = \begin{bmatrix}
\boldsymbol{\beta}_1 &amp; \cdots &amp; \boldsymbol{\beta}_k
\end{bmatrix}
\]</span>
Where <span class="math inline">\(\boldsymbol{\beta}_i\)</span> is a vector of length <span class="math inline">\(m+1\)</span> containing regression
coefficients for each covariate on the <span class="math inline">\(i\)</span>th variate of interest, the first element
in <span class="math inline">\(\boldsymbol{\beta}_i\)</span> being the intercept. We also
wish to estimate
<span class="math display">\[
\Sigma \ | \ \boldsymbol{X} =
\begin{bmatrix}
\sigma^2_1 \ | \ \boldsymbol{X} &amp; \rho\sigma_1\sigma_2 \ | \ \boldsymbol{X} \\
\rho\sigma_1\sigma_2 \ | \ \boldsymbol{X} &amp; \sigma^2_2 \ | \ \boldsymbol{X}
\end{bmatrix}
\]</span>
That is, the covariance matrix of the variates of interest conditioned upon the
covariates, for task <span class="math inline">\(Y_1\)</span> and task <span class="math inline">\(Y_2\)</span> i.e., when <span class="math inline">\(k=2\)</span>. If we wish to test for
a deficit, that is <span class="math inline">\(k = 1\)</span> then <span class="math inline">\(\Sigma \ | \ \boldsymbol{X}\)</span> is a <span class="math inline">\(1\times1\)</span>
matrix containing the conditional variance of the variate of interest.
We assume <span class="math inline">\(\Sigma\)</span> not to vary with the covariates.</p>
<p>The procedure will be outlined in the general case, that is for <span class="math inline">\(k = 1\)</span>
or <span class="math inline">\(k = 2\)</span>. The main difference between testing for abnormality on a single
variate and testing for abnormal discrepancy between two variates is the recommended
specification of the prior.</p>
<p>Let <span class="math inline">\(\boldsymbol{X}\)</span> be the <span class="math inline">\(n \times m+1\)</span> design matrix on which we regress
<span class="math inline">\(\boldsymbol{Y}\)</span>, the <span class="math inline">\(n \times k\)</span> response matrix.
<span class="math display">\[
\boldsymbol{X} =
\begin{bmatrix}
1 &amp; x_{11} &amp; \cdots &amp; x_{1m} \\
\vdots &amp; \vdots &amp; \ddots &amp; \vdots \\
1 &amp; x_{n1} &amp; \cdots &amp; x_{nm}
\end{bmatrix},\ \
\boldsymbol{Y} =
\begin{bmatrix}
 y_{11} &amp; \cdots &amp; y_{1k} \\
 \vdots &amp; \ddots &amp; \vdots \\
 y_{n1} &amp; \cdots &amp; y_{nk}
\end{bmatrix}
\]</span>
The data estimates of <span class="math inline">\(\boldsymbol{B}\)</span> and <span class="math inline">\(\Sigma\)</span> are then
<span class="math display">\[
\boldsymbol{B}^* = (\boldsymbol{X}&#39;\boldsymbol{X})^{-1}\boldsymbol{X}&#39;\boldsymbol{Y} \ \text{and} \
\Sigma^* = \frac{1}{n-m-1}(\boldsymbol{Y}-\boldsymbol{X}\boldsymbol{B}^*)&#39;(\boldsymbol{Y}-\boldsymbol{X}\boldsymbol{B}^*)
\]</span>
For the “standard theory” prior the posterior of <span class="math inline">\(\Sigma\)</span> is an inverse
Wishart distribution with <span class="math inline">\(df = n - m\)</span> when <span class="math inline">\(k=2\)</span> and <span class="math inline">\(df=n-m-1\)</span> when <span class="math inline">\(k = 1\)</span> <span class="citation"><a href="#ref-tiaoBayesianEstimationMultivariate1964" role="doc-biblioref">Tiao and Zellner</a> (<a href="#ref-tiaoBayesianEstimationMultivariate1964" role="doc-biblioref">1964</a>)</span> and scale matrix <span class="math inline">\((n-m-1)\Sigma^*\)</span>.
For each iteration we generate an estimate of <span class="math inline">\(\Sigma\)</span> from this distribution.
For the “calibrated” prior (only used for <span class="math inline">\(k=2\)</span>) the steps described in
<a href="#BSDT">2.3.2</a> are followed and we use <span class="math inline">\(\pmb{S}^* = (n-m-2)\pmb{S}/(n-m-1)\)</span> as the
scale matrix when we sample from an inverse Wishart distribution on <span class="math inline">\((n-m-2)\)</span>
degrees of freedom, where <span class="math inline">\(\pmb{S} = (n-m-1)\Sigma^*\)</span>. The generated
observation from either method is denoted <span class="math inline">\(\hat{\Sigma}_{(i)}\)</span>.
We have</p>
<p><span class="math display" id="eq:sigma">\[\begin{equation}
\hat{\Sigma}_{(i)}=[\hat{s}^2_{(i)}] \ \text{when} \ k=1 \ \text{and} \
\hat{\Sigma}_{(i)} =
\begin{bmatrix}
\hat{s}^2_{1(i)} &amp; \hat{s}_{12(i)}  \\
\hat{s}_{12(i)}  &amp; \hat{s}^2_{2(i)}
\end{bmatrix} \ \text{when} \ k=2 \
\tag{2.6}
\label{eq:sigma}
\end{equation}\]</span></p>
<p><span class="math inline">\(\boldsymbol{B}^*\)</span> will be an <span class="math inline">\((m+1) \times k\)</span> matrix. We turn this into a <span class="math inline">\(k(m + 1) \times 1\)</span>
vector by concatenating the colums of regression coefficients in <span class="math inline">\(\boldsymbol{B}^*\)</span>, such
that <span class="math inline">\(\boldsymbol{B}^*_{\text{vec}}=(\boldsymbol{\beta}^{*&#39;}_1, ...,\boldsymbol{\beta}^{*&#39;}_k)&#39;\)</span>.
Then this vector is the data estimate for
<span class="math inline">\(\boldsymbol{B}_{\text{vec}}=(\boldsymbol{\beta}&#39;_1, ...,\boldsymbol{\beta}&#39;_k)&#39;\)</span>.
Take the kronecker product <span class="math inline">\(\boldsymbol{\hat\Sigma}_{(i)} \otimes (\boldsymbol{X&#39;X})^{-1}\)</span> and
denote this <span class="math inline">\(\boldsymbol{\Lambda}_{(i)}\)</span>. Then the posterior of <span class="math inline">\(\boldsymbol{B}_{\text{vec}}|\boldsymbol{\hat\Sigma}_{(i)}\)</span>
is a multivariate normal distribution with mean vector <span class="math inline">\(\boldsymbol{B}^*_{\text{vec}}\)</span>
and variance-covariance matrix <span class="math inline">\(\boldsymbol{\Lambda}_{(i)}\)</span>. Draw a random value
from this distribution such that
<span class="math inline">\(\hat{\boldsymbol{B}}^*_{\text{vec(i)}} =(\hat{\boldsymbol{\beta}}&#39;_{1(i)}, ...,\hat{\boldsymbol{\beta}}&#39;_{k(i)})&#39;\)</span>
and <span class="math inline">\(\hat{\boldsymbol{B}}_{(i)} = (\hat{\boldsymbol{\beta}}_{1(i)}, ...,\hat{\boldsymbol{\beta}}_{k(i)})\)</span>,
where each <span class="math inline">\(\hat{\boldsymbol{\beta}}_{j(i)}\)</span> is a vector of length <span class="math inline">\(m+1\)</span> and <span class="math inline">\(\hat{\boldsymbol{B}}_{(i)}\)</span>
an <span class="math inline">\(m+1 \times k\)</span> matrix.</p>
<p>Let <span class="math inline">\(\boldsymbol{x}^*\)</span> be a vector of the case’s values on the covariates.
The conditional values for the case on the tasks of interest
is then
<span class="math display">\[
\hat{\boldsymbol{\mu}}_{(i)} = \hat{\boldsymbol{B}}_{(i)}\boldsymbol{x}^*
\]</span></p>
<p>We now estimate the effect size of the case using the conditional
estimations derived above. Depending on whether we are testing for a
deficit or a discrepancy (i.e., whether <span class="math inline">\(k=1\)</span> or <span class="math inline">\(k=2\)</span>) the calculations
of the effect sizes differ. <span class="citation"><a href="#ref-crawfordComparingSingleCase2011" role="doc-biblioref">Crawford, Garthwaite, and Ryan</a> (<a href="#ref-crawfordComparingSingleCase2011" role="doc-biblioref">2011</a>)</span> call these effect
sizes <span class="math inline">\(Z_{CCC}\)</span> and <span class="math inline">\(Z_{DCCC}\)</span> for a deficit and a discrepancy respectively.
They are similar to <span class="math inline">\(Z_{CC}\)</span> (Equation <a href="#eq:zcc">(2.2)</a>) and <span class="math inline">\(Z_{DCC}\)</span> (Equation <a href="#eq:PJ">(2.4)</a>), however,
the extra <span class="math inline">\(C\)</span> in the subscript indicates that they are conditional on
covariates. Denote <span class="math inline">\(y^*_1\)</span> and <span class="math inline">\(y^*_2\)</span> as the case’s scores on the two variates
of interest. Given that we want to estimate deficiency of a case on <span class="math inline">\(Y_1\)</span>, we
calculate
<span class="math display" id="eq:zccc">\[\begin{equation}
\hat{Z}_{CCC(i)} = \frac{y^*_1-\hat{\mu}_{(i)}}{\hat{s}^2_{(i)}}
\tag{2.7}
\label{eq:zccc}
\end{equation}\]</span>
For <span class="math inline">\(Z_{DCCC}\)</span> we have two conditional means which will be denoted
<span class="math inline">\(\hat{\mu}_{1(i)}\)</span> and <span class="math inline">\(\hat{\mu}_{2(i)}\)</span> for <span class="math inline">\(Y_1\)</span> and <span class="math inline">\(Y_2\)</span>
respectively. We then calculate
<span class="math display" id="eq:zdccc">\[\begin{equation}
\hat{Z}_{DCCC(i)} = \frac{\frac{y^*_1-\hat{\mu}_{1(i)}}{\hat{s}_{1(i)}}-\frac{y^*_2-\hat{\mu}_{2(i)}}
{\hat{s}_{2(i)}}}{\sqrt{2-2\hat{\rho}_{12(i)}}}
\tag{2.8}
\label{eq:zdccc}
\end{equation}\]</span>
Where <span class="math inline">\(\hat{s}_{1(i)}\)</span> and <span class="math inline">\(\hat{s}_{2(i)}\)</span> are conditional
standard deviations obtained from <span class="math inline">\(\hat{\Sigma}_{(i)}\)</span> in Equation <a href="#eq:sigma">(2.6)</a>.
The conditional correlation between <span class="math inline">\(Y_1\)</span> and <span class="math inline">\(Y_2\)</span> in the denominator is given by
<span class="math display">\[\hat{\rho}_{12(i)} = \frac{\hat{s}_{12(i)}}{\sqrt{\hat{s}^2_{1(i)}\hat{s}^2_{2(i)}}}\]</span></p>
<p>We then find the tail area under the standard normal distribution that is less or greater than
<span class="math inline">\(\hat{Z}_{CCC(i)}\)</span> or <span class="math inline">\(\hat{Z}_{DCCC(i)}\)</span> depending on the problem at hand and the alternative
hypothesis specified. Denote the value obtained <span class="math inline">\(\hat{p}_{(i)}\)</span> which then
is an estimate of <span class="math inline">\(p\)</span>. If testing for a deficit we would have:
<span class="math display">\[
\hat{p}_{(i)}= \Phi(\hat{Z}_{CCC(i)})
\]</span></p>
<p>Iterating these steps a large number of times will yield a distribution of
<span class="math inline">\(\hat{p}\)</span>, the mean of which is taken as the point estimate of <span class="math inline">\(p\)</span>. This
estimate is used for significance testing and if multiplied by 100 it will
give an estimate of the percentage of controls expected to exhibit a more
extreme score than the case. If repeated e.g., 1000 times, the
25th smallest and 25th largest <span class="math inline">\(\hat{p}_{(i)}\)</span> is the lower and upper boundaries of
the 95% credible interval for <span class="math inline">\(p\)</span>.</p>
<p>To obtain a point estimate of <span class="math inline">\(Z_{CCC}\)</span> and <span class="math inline">\(Z_{DCCC}\)</span> we use Equation <a href="#eq:zccc">(2.7)</a>
and <a href="#eq:zdccc">(2.8)</a>, but use the conditional means, standard deviations
and correlation calculated directly from the control sample.
The <span class="math inline">\(1-\alpha\)</span> credible intervals for these
effect sizes are given by the <span class="math inline">\(\alpha/2\)</span> and <span class="math inline">\(1-\alpha/2\)</span> quantiles
of the sampled distribution of <span class="math inline">\(Z_{CCC}\)</span> or <span class="math inline">\(Z_{DCCC}\)</span>. That is, just as
for <span class="math inline">\(p\)</span>, if repeated e.g., 1000 times, the
25th smallest and 25th largest value of <span class="math inline">\(\hat{Z}_{CCC(i)}\)</span> or <span class="math inline">\(\hat{Z}_{DCCC(i)}\)</span>
is the lower and upper boundaries of
the 95% credible interval for <span class="math inline">\(Z_{CCC}\)</span> or <span class="math inline">\(Z_{DCCC}\)</span>.</p>
</div>
</div>
</div>
<div id="section3" class="section level1" number="3">
<h1><span class="header-section-number">3</span> The <code>singcar</code> package</h1>
<div id="functions-for-testing-abnormality" class="section level2" number="3.1">
<h2><span class="header-section-number">3.1</span> Functions for testing abnormality</h2>
<table>
<caption>Main functions for significance testing of abnormality when using small control samples and principal relevant reference in prior literature.</caption>
<colgroup>
<col width="25%" />
<col width="25%" />
<col width="25%" />
<col width="25%" />
</colgroup>
<thead>
<tr class="header">
<th>Name</th>
<th>Function</th>
<th>Source</th>
<th>Reference</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Test of deficit</td>
<td><code>TD()</code></td>
<td><span class="citation"><a href="#ref-crawfordComparingIndividualTest1998" role="doc-biblioref">Crawford and Howell</a> (<a href="#ref-crawfordComparingIndividualTest1998" role="doc-biblioref">1998</a>)</span></td>
<td>Equation <a href="#eq:TD">(2.1)</a></td>
</tr>
<tr class="even">
<td>Bayesian test of deficit</td>
<td><code>BTD()</code></td>
<td><span class="citation"><a href="#ref-crawfordComparisonSingleCase2007" role="doc-biblioref">Crawford and Garthwaite</a> (<a href="#ref-crawfordComparisonSingleCase2007" role="doc-biblioref">2007</a>)</span></td>
<td>Section <a href="#BTD">2.3.1</a></td>
</tr>
<tr class="odd">
<td>Bayesian test of deficit with covariates</td>
<td><code>BTD_cov()</code></td>
<td><span class="citation"><a href="#ref-crawfordComparingSingleCase2011" role="doc-biblioref">Crawford, Garthwaite, and Ryan</a> (<a href="#ref-crawfordComparingSingleCase2011" role="doc-biblioref">2011</a>)</span></td>
<td>Section <a href="#cov">2.3.3</a></td>
</tr>
<tr class="even">
<td>Unstandardised difference test</td>
<td><code>UDT()</code></td>
<td><span class="citation"><a href="#ref-crawfordTestingSuspectedImpairments2005" role="doc-biblioref">Crawford and Garthwaite</a> (<a href="#ref-crawfordTestingSuspectedImpairments2005" role="doc-biblioref">2005</a>)</span></td>
<td>Equation <a href="#eq:UDT">(2.3)</a></td>
</tr>
<tr class="odd">
<td>Revised standardised difference test</td>
<td><code>RSDT()</code></td>
<td><span class="citation"><a href="#ref-crawfordTestingSuspectedImpairments2005" role="doc-biblioref">Crawford and Garthwaite</a> (<a href="#ref-crawfordTestingSuspectedImpairments2005" role="doc-biblioref">2005</a>)</span></td>
<td>Equation <a href="#eq:RSDT">(2.5)</a></td>
</tr>
<tr class="even">
<td>Bayesian standardised difference test</td>
<td><code>BSDT()</code></td>
<td><span class="citation"><a href="#ref-crawfordComparisonSingleCase2007" role="doc-biblioref">Crawford and Garthwaite</a> (<a href="#ref-crawfordComparisonSingleCase2007" role="doc-biblioref">2007</a>)</span></td>
<td>Section <a href="#BSDT">2.3.2</a></td>
</tr>
<tr class="odd">
<td>Bayesian standardised difference test with covariates</td>
<td><code>BSDT_cov()</code></td>
<td><span class="citation"><a href="#ref-crawfordComparingSingleCase2011" role="doc-biblioref">Crawford, Garthwaite, and Ryan</a> (<a href="#ref-crawfordComparingSingleCase2011" role="doc-biblioref">2011</a>)</span></td>
<td>Section <a href="#cov">2.3.3</a></td>
</tr>
</tbody>
</table>
<p>To facilitate meta-analyses of studies using case-control comparisons,
all functions in the table above can take both summary statistics as
input as well as raw data. The output will be a list set to class <code>&quot;htest&quot;</code>,
for which the generic function <code>print</code> have a method. To use the package,
begin by installing and loading it:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">install.packages</span>(<span class="st">&quot;singcar&quot;</span>)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(<span class="st">&quot;singcar&quot;</span>)</span></code></pre></div>
</div>
<div id="example-from-neuropsychology" class="section level2" number="3.2">
<h2><span class="header-section-number">3.2</span> Example from neuropsychology</h2>
<p>The package comes with the dataset <code>size_weight_illusion</code>, a
neuropsychological dataset from an investigation of the size-weight illusion in
DF, a patient with visual form agnosia following bilateral lesions to the
lateral occipital complex <span class="citation">(<a href="#ref-hassanSizeweightIllusionVisual2020" role="doc-biblioref">Hassan et al. 2020</a>)</span>. The size-weight illusion
is a perceptual phenomenon in which smaller objects are perceived as heavier
during lifting than larger objects of equal weight <span class="citation">(<a href="#ref-buckinghamGettingGripHeaviness2014" role="doc-biblioref">Buckingham 2014</a>)</span>.
The illusion implies that sensory cues about object size affect the perception
of weight. It has been suggested that patient DF does not experience this
illusion in the same way as the healthy population when only visual cues about
object size are available <span class="citation">(<a href="#ref-dijkermanVisuomotorPerformancePatient2004a" role="doc-biblioref">Dijkerman et al. 2004</a>)</span>. In contrast, when kinaesthetic (tactile) cues are
provided it is suggested that DF’s experience of the illusion is unaffected
by her brain damage. In other words, patient DF was expected to have a deficit
in the visual size-weight illusion and exhibit an abnormally large discrepancy
(dissociation) between visual and kinaesthetic size-weight illusions. The
dataset consists of data from patient DF and 28 control participants, with the
variables sex, age and visual as well as kinaesthetic size-weight illusion. The
measure of the size-weight illusion is a scaled measure expressing the number of
grams weight difference perceived per cubic cm of volume change. Below follows
examples of how to analyse this dataset using the tests provided in
<code>singcar</code>.</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(size_weight_illusion)</span></code></pre></div>
<pre><code>##   GROUP PPT    SEX YRS      V_SWI      K_SWI
## 1    SC  DF Female  65 0.02814921 0.10012712
## 2    HC E01 Female  70 0.21692634 0.21792930
## 3    HC E02   Male  64 0.17223226 0.26338899
## 4    HC E03 Female  63 0.07138049 0.09331700
## 5    HC E04 Female  65 0.10186453 0.25938045
## 6    HC E05 Female  66 0.15911439 0.08922615</code></pre>
<div id="testing-for-a-deficit" class="section level3" number="3.2.1">
<h3><span class="header-section-number">3.2.1</span> Testing for a deficit</h3>
<p>The simplest way to test for an abnormality on a single variate is
to use the frequentist test of deficit. Start by extracting patient (patient DF
is the first observation) and control data from the relevant variate, in this
case the visual size-weight illusion:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a>PAT_VSWI <span class="ot">&lt;-</span> size_weight_illusion[<span class="dv">1</span>, <span class="st">&quot;V_SWI&quot;</span>]</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>CON_VSWI <span class="ot">&lt;-</span> size_weight_illusion[<span class="sc">-</span><span class="dv">1</span>, <span class="st">&quot;V_SWI&quot;</span>] </span></code></pre></div>
<p>Using the function <code>TD()</code> we then apply the formula in Equation <a href="#eq:TD">(2.1)</a>.
The argument <code>conf_int_spec</code> specifies how fine grained the search
algorithm for the confidence interval should be. The arguments <code>sd</code>
and <code>sample_size</code> can be given if the test should be based on summary
statistics rather than raw data, the <code>controls</code> argument should then be the
mean of the control sample.</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="fu">TD</span>(<span class="at">case =</span> PAT_VSWI,</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>   <span class="at">controls =</span> CON_VSWI,</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>   <span class="at">sd =</span> <span class="cn">NULL</span>,</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>   <span class="at">sample_size =</span> <span class="cn">NULL</span>,</span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>   <span class="at">alternative =</span> <span class="st">&quot;less&quot;</span>,</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>   <span class="at">conf_int =</span> <span class="cn">TRUE</span>,</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>   <span class="at">conf_level =</span> <span class="fl">0.95</span>,</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>   <span class="at">conf_int_spec =</span> <span class="fl">0.01</span>,</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>   <span class="at">na.rm =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<pre><code>## 
##  Test of Deficit
## 
## data:  Case = 0.03, Controls (m = 0.16, sd = 0.08, n = 28)
## t = -1.7243, df = 27, p-value = 0.04804
## alternative hypothesis: true diff. between case and controls is less than 0
## sample estimates:
##   Std. case score (Z-CC), 95% CI [-2.34, -1.15] 
##                                       -1.754857 
## Proportion below case (%), 95% CI [0.95, 12.47] 
##                                        4.804003</code></pre>
<p>This can similarly be tested with the Bayesian analogue which has a very similar syntax.
This test yields an output that converges to that of TD as the argument for the
number of iterations (<code>iter</code>) increase. The degrees of freedom shown in the
output below is the degrees of freedom for the <span class="math inline">\(\chi^2\)</span> distribution from which
we sample <span class="math inline">\(\psi\)</span>, as described in Section <a href="#BTD">2.3.1</a>.</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="fu">BTD</span>(<span class="at">case =</span> PAT_VSWI,</span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>    <span class="at">controls =</span> CON_VSWI,</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>    <span class="at">sd =</span> <span class="cn">NULL</span>,</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>    <span class="at">sample_size =</span> <span class="cn">NULL</span>,</span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a>    <span class="at">alternative =</span> <span class="st">&quot;less&quot;</span>,</span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a>    <span class="at">int_level =</span> <span class="fl">0.95</span>,</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    <span class="at">iter =</span> <span class="dv">10000</span>,</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>    <span class="at">na.rm =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<pre><code>## 
##  Bayesian Test of Deficit
## 
## data:  Case = 0.03, Controls (m = 0.16, sd = 0.08, n = 28)
## df = 27, p-value = 0.04821
## alternative hypothesis: true diff. between case and controls is less than 0
## sample estimates:
##   Std. case score (Z-CC), 95% CI [-2.35, -1.15] 
##                                       -1.754857 
## Proportion below case (%), 95% CI [0.94, 12.60] 
##                                        4.821283</code></pre>
<p>If the control sample for a study is not appropriately matched to the case on
variables such as, for example, age or education level it is appropriate to use tests
that account for this by allowing for the inclusion of covariates. Including
theoretically sound covariates is often a good idea. <span class="citation"><a href="#ref-crawfordComparingSingleCase2011" role="doc-biblioref">Crawford, Garthwaite, and Ryan</a> (<a href="#ref-crawfordComparingSingleCase2011" role="doc-biblioref">2011</a>)</span>
recommends however to only include a covariate if it correlates <span class="math inline">\(\geq 0.3\)</span> with
the variate of interest, because of the loss of degrees of freedom.</p>
<p>The function <code>BTD_cov()</code> allows for the inclusion of covariates and therefore to
assess the patient on the task of interest by essentially comparing him/her to
the controls with the same score on the covariate. Even though the correlation
between age and visual size-weight illusion is <span class="math inline">\(&lt; 0.3\)</span> it is included here as
a coviariate for demonstrative purposes. Start again by extracting the
scores on the covariate for the patient and for the control participants.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a>PAT_age <span class="ot">&lt;-</span> size_weight_illusion[<span class="dv">1</span>, <span class="st">&quot;YRS&quot;</span>] </span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a>CON_age <span class="ot">&lt;-</span> size_weight_illusion[<span class="sc">-</span><span class="dv">1</span>, <span class="st">&quot;YRS&quot;</span>]</span></code></pre></div>
<p>Since <code>BTD_cov()</code> is somewhat computationally intense, the number of
iterations has been reduced in the example compared to <code>BTD()</code>. For actual analysis the number
of iterations should be based on required precision. It should be noted that
there is no restriction on the number of covariates used as long as <span class="math inline">\(n &gt; m+1\)</span>. If more than one
covariate is used the case scores should be given as a vector of values
and the control scores should be given as a data frame or matrix with the
same number of columns as the number of values in the covariate vector of the case.</p>
<p>If summary statistics are used instead of raw data, the argument <code>use_sumstats</code>
must be set to <code>TRUE</code> and the correlation matrix for the covariates
and variate of interest must be given as well as the sample size. In addition,
the <code>control_covar</code> argument must be supplied as an <span class="math inline">\(m \times 2\)</span>
matrix or data frame giving the mean of the covariate(s) in the first column
and the standard deviation in the second. The degrees of freedom shown in the
output below is the degrees of freedom for the inverse Wishart distribution from which
we sample <span class="math inline">\(\psi\)</span>, as described in Section <a href="#cov">2.3.3</a>.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span class="fu">BTD_cov</span>(<span class="at">case_task =</span> PAT_VSWI,</span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>        <span class="at">case_covar =</span> PAT_age,</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>        <span class="at">control_task =</span> CON_VSWI,</span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>        <span class="at">control_covar =</span> CON_age,</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a>        <span class="at">alternative =</span> <span class="st">&quot;less&quot;</span>,</span>
<span id="cb10-6"><a href="#cb10-6" aria-hidden="true" tabindex="-1"></a>        <span class="at">int_level =</span> <span class="fl">0.95</span>,</span>
<span id="cb10-7"><a href="#cb10-7" aria-hidden="true" tabindex="-1"></a>        <span class="at">iter =</span> <span class="dv">1000</span>,</span>
<span id="cb10-8"><a href="#cb10-8" aria-hidden="true" tabindex="-1"></a>        <span class="at">use_sumstats =</span> <span class="cn">FALSE</span>,</span>
<span id="cb10-9"><a href="#cb10-9" aria-hidden="true" tabindex="-1"></a>        <span class="at">cor_mat =</span> <span class="cn">NULL</span>,</span>
<span id="cb10-10"><a href="#cb10-10" aria-hidden="true" tabindex="-1"></a>        <span class="at">sample_size =</span> <span class="cn">NULL</span>)</span></code></pre></div>
<pre><code>## 
##  Bayesian Test of Deficit with Covariates
## 
## data:  Case = 0.03, Controls (m = 0.16, sd = 0.08, n = 28)
## df = 26, p-value = 0.05173
## alternative hypothesis: true diff. between case and controls is less than 0
## sample estimates:
##  Std. case score (Z-CCC), 95% CI [-2.30, -1.10] 
##                                       -1.749556 
## Proportion below case (%), 95% CI [1.08, 13.47] 
##                                        5.172973</code></pre>
</div>
<div id="testing-for-a-dissociation" class="section level3" number="3.2.2">
<h3><span class="header-section-number">3.2.2</span> Testing for a dissociation</h3>
<p>For assessing abnormal discrepancy between two variates the simplest
function to use is the unstandardised difference test, Equation <a href="#eq:UDT">(2.3)</a>.
This test is in <code>singcar</code>called by the function <code>UDT()</code>. However, one
should use this only if the variates are known to come from equivalent distributions.
Otherwise, tests that can evaluate standardised scores
without inflating Type I errors should be used. In the frequentist framework the
appropriate test for this is the RSDT, Equation <a href="#eq:RSDT">(2.5)</a>. In this example we wish
to estimate and test the abnormality of the discrepancy between visual
and kinaesthetic size-weight illusion in patient DF. That is, we want to compare the difference
between the variates exhibited by the patient and the distribution of differences
in the healthy control sample. Again, start by extracting
the patient and control scores for the second variate of interest.</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a>PAT_KSWI <span class="ot">&lt;-</span> size_weight_illusion[<span class="dv">1</span>, <span class="st">&quot;K_SWI&quot;</span>] </span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>CON_KSWI <span class="ot">&lt;-</span> size_weight_illusion[<span class="sc">-</span><span class="dv">1</span>, <span class="st">&quot;K_SWI&quot;</span>] </span></code></pre></div>
<p>Using the function <code>RSDT()</code> we then apply the formula in
Equation <a href="#eq:RSDT">(2.5)</a>. This test is most often used two-sided due to the fact the the
sign of the discrepancy solely depends on the order of the input.
This function does, however, not provide any confidence intervals. The syntax of
<code>UDT()</code> is very similar to that of <code>RSDT()</code>, the main difference being
options for confidence intervals as shown for <code>TD()</code>. If summary statistics
are used then the additional argument <code>r_ab</code>, which is the sample
correlation, must be set as well as the sample size, standard deviation and mean
for both variates.</p>
<div class="sourceCode" id="cb13"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span class="fu">RSDT</span>(<span class="at">case_a =</span> PAT_VSWI,</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>     <span class="at">case_b =</span> PAT_KSWI,</span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">controls_a =</span> CON_VSWI,</span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>     <span class="at">controls_b =</span> CON_KSWI,</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>     <span class="at">sd_a =</span> <span class="cn">NULL</span>,</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>     <span class="at">sd_b =</span> <span class="cn">NULL</span>,</span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a>     <span class="at">sample_size =</span> <span class="cn">NULL</span>,</span>
<span id="cb13-8"><a href="#cb13-8" aria-hidden="true" tabindex="-1"></a>     <span class="at">r_ab =</span> <span class="cn">NULL</span>,</span>
<span id="cb13-9"><a href="#cb13-9" aria-hidden="true" tabindex="-1"></a>     <span class="at">alternative =</span> <span class="st">&quot;two.sided&quot;</span>,</span>
<span id="cb13-10"><a href="#cb13-10" aria-hidden="true" tabindex="-1"></a>     <span class="at">na.rm =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<pre><code>## 
##  Revised Standardised Difference Test
## 
## data:  Case A: 0.03, B: 0.10, Ctrl. A (m, sd): (0.16, 0.08), B: (0.18, 0.10)
## approx. abs. t = 1.015, df = 27, p-value = 0.3191
## alternative hypothesis: true difference between tasks is not equal to 0
## sample estimates:
## Std. case score, task A (Z-CC) Std. case score, task B (Z-CC) 
##                     -1.7548574                     -0.7836956 
##  Std. task discrepancy (Z-DCC)      Proportion below case (%) 
##                     -1.0647889                     15.9560625</code></pre>
<p>The Bayesian analogue of this test is recommended over the RSDT
because it keeps a better control
over Type I errors when the case exhibits extreme deficits on both variates but
no discrepancy between them <span class="citation">(<a href="#ref-crawfordComparisonSingleCase2007" role="doc-biblioref">Crawford and Garthwaite 2007</a>)</span>.
The syntax of the two functions is similar, but the <code>BSDT()</code> comes with more
optional arguments. For example, one has the option of applying this test
without standardising the variates by setting the argument <code>unstandardised</code>
to <code>TRUE</code>. The output then converges to that of the frequentist UDT.
Furthermore, one can choose between priors. Setting the
argument <code>calibrated</code> to <code>FALSE</code> specifies the use of the “standard
theory” prior. If left to the default (<code>TRUE</code>) an accept-reject algorithm
is deployed for each simulation of <span class="math inline">\(\Sigma\)</span>, as described in Section
<a href="#BSDT">2.3.2</a>. This default prior has been shown to have better frequentist
properties for estimating <span class="math inline">\(\rho\)</span> and differences between means in a bivariate
normal distributions <span class="citation">(<a href="#ref-bergerObjectivePriorsBivariate2008" role="doc-biblioref">Berger and Sun 2008</a>)</span> and is therefore
the default and recommended choice.</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span class="fu">BSDT</span>(<span class="at">case_a =</span> PAT_VSWI,</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a>     <span class="at">case_b =</span> PAT_KSWI,</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a>     <span class="at">controls_a =</span> CON_VSWI,</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a>     <span class="at">controls_b =</span> CON_KSWI,</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a>     <span class="at">sd_a =</span> <span class="cn">NULL</span>,</span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a>     <span class="at">sd_b =</span> <span class="cn">NULL</span>,</span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a>     <span class="at">sample_size =</span> <span class="cn">NULL</span>,</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>     <span class="at">r_ab =</span> <span class="cn">NULL</span>,</span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a>     <span class="at">alternative =</span> <span class="st">&quot;two.sided&quot;</span>,</span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a>     <span class="at">int_level =</span> <span class="fl">0.95</span>,</span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a>     <span class="at">iter =</span> <span class="dv">10000</span>,</span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a>     <span class="at">unstandardised =</span> <span class="cn">FALSE</span>,</span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a>     <span class="at">calibrated =</span> <span class="cn">TRUE</span>,</span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a>     <span class="at">na.rm =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<pre><code>## 
##  Bayesian Standardised Difference Test
## 
## data:  Case A: 0.03, B: 0.10, Ctrl. A (m, sd): (0.16,0.08), B: (0.18,0.10)
## df = 26, p-value = 0.3245
## alternative hypothesis: true difference between tasks is not equal to 0
## sample estimates:
##                  Std. case score, task A (Z-CC) 
##                                      -1.7548574 
##                  Std. case score, task B (Z-CC) 
##                                      -0.7836956 
## Std. discrepancy (Z-DCC), 95% CI [-1.69, -0.42] 
##                                      -1.0647889 
## Proportion below case (%), 95% CI [4.51, 33.81] 
##                                      16.2259126</code></pre>
<p>If analysing discrepancies between variates in the presence of covariates the syntax is slightly
different, requiring that one specifies the case’s scores on the variates of
interest as a vector and the control scores as a data frame or matrix.
One has the option to choose between the “calibrated” and “standard theory”
prior, just as for <code>BSDT()</code>, where <code>calibrated = TRUE</code> is the
recommended and default behaviour. If using summary statistics
<code>use_sumstats</code> must be set to <code>TRUE</code> and the summary input should be
supplied to the arguments <code>control_tasks</code>/<code>control_covar</code> as data
frames or matrices with the means of each variable represented by the first
column and the standard deviations by the second. The case’s scores should
be supplied as vectors.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">BSDT_cov</span>(<span class="at">case_tasks =</span> <span class="fu">c</span>(PAT_VSWI, PAT_KSWI),</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>         <span class="at">case_covar =</span> PAT_age,</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">control_tasks =</span> <span class="fu">cbind</span>(CON_VSWI, CON_KSWI),</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">control_covar =</span> CON_age,</span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>         <span class="at">alternative =</span> <span class="st">&quot;two.sided&quot;</span>,</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>         <span class="at">int_level =</span> <span class="fl">0.95</span>,</span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>         <span class="at">calibrated =</span> <span class="cn">TRUE</span>,</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>         <span class="at">iter =</span> <span class="dv">1000</span>,</span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>         <span class="at">use_sumstats =</span> <span class="cn">FALSE</span>,</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>         <span class="at">cor_mat =</span> <span class="cn">NULL</span>,</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>         <span class="at">sample_size =</span> <span class="cn">NULL</span>)</span></code></pre></div>
<pre><code>## 
##  Bayesian Standardised Difference Test with Covariates
## 
## data:  Case A = 0.03, B = 0.10, Ctrl. (m, sd) A: (0.16,0.08), B: (0.18,0.10)
## df = 25, p-value = 0.3383
## alternative hypothesis: true difference between tasks is not equal to 0
## sample estimates:
##                   Std. case score, task A (Z-CC) 
##                                        -1.754857 
##                   Std. case score, task B (Z-CC) 
##                                        -0.783696 
## Std. discrepancy (Z-DCCC), 95% CI [-1.60, -0.38] 
##                                        -1.064152 
##  Proportion below case (%), 95% CI [5.53, 35.32] 
##                                        16.920000</code></pre>
</div>
<div id="power-calculators" class="section level3" number="3.2.3">
<h3><span class="header-section-number">3.2.3</span> Power calculators</h3>
<p>A further capacity of <code>singcar</code>is that it can be used to calculate
statistical power of the tests. The notion of power when comparing cases to
control samples have been somewhat overlooked for this class of statistical tests.
In recent work <span class="citation">(<a href="#ref-mcintoshPowerCalculationsSinglecase2020" role="doc-biblioref">McIntosh and Rittmo 2020</a>)</span>, we argued that,
even though power is inherently limited in this paradigm, a priori calculations are
still useful for study design and interpretation in neuropsychological and other applications.
Calculating power for the test of deficit is similar to calculating power for
any <span class="math inline">\(t\)</span> test and can be done analytically.
<span class="math display" id="eq:TDpower">\[\begin{equation} power = 1 - \beta =
T_{n-1}\left(t_{\alpha, \ n-1} \Bigg\rvert \frac{x^* - \overline{x}}{\sigma
\sqrt{\frac{n+1}{n}}}\right) 
\tag{3.1}
\label{eq:TDpower} 
\end{equation}\]</span>
Where <span class="math inline">\(T_{n-1}(.\rvert \theta)\)</span> is the cumulative distribution function for the
non-central <span class="math inline">\(t\)</span> distribution with <span class="math inline">\(n-1\)</span> degrees of freedom and non-centrality
parameter <span class="math inline">\(\frac{y^* - \overline{y}}{\sigma \sqrt{\frac{n+1}{n}}}\)</span> (i.e., TD, Equation
<a href="#eq:TD">(2.1)</a> and <span class="math inline">\(t_{\alpha, \ n-1}\)</span> is the <span class="math inline">\(\alpha\)</span> quantile of the 
<span class="math inline">\(t\)</span> distribution on <span class="math inline">\(n-1\)</span> degrees of freedom (note that this is for a one-sided
test). For the unstandardised difference test power is calculated in an
analogous way by putting Equation <a href="#eq:UDT">(2.3)</a> as the non-centrality parameter. Deriving
power for the other functions in an analytic manner is however not possible (the
RSDT is only approximately <span class="math inline">\(t\)</span> distributed) and a Monte Carlo approach has been
used for these tests. To call any power calculator in the package one simply
uses the function names with <code>_power</code> added as a suffix.</p>
<p>So, for example, to calculate power for the test of deficit we call <code>TD_power()</code>.
The expected case score and either sample size or desired power must
be supplied. The mean and standard deviation of the control sample
can also be specified with the arguments <code>mean</code> and <code>sd</code>.
If not, they take the default values of 0 and 1 respectively so
that the case score is interpreted as distance from the mean
in standard deviations. A conventional <span class="math inline">\(\alpha\)</span>-level of
<span class="math inline">\(0.05\)</span> is assumed if nothing else is supplied. The alternative
hypothesis can also be specified by the argument <code>alternative</code>:
specify <code>&quot;less&quot;</code> (default) or <code>&quot;greater&quot;</code> for a one-tailed test, specify
<code>&quot;two.sided&quot;</code> for a two-tailed test.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">TD_power</span>(<span class="at">case =</span> <span class="dv">70</span>,</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>         <span class="at">mean =</span> <span class="dv">100</span>,</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">sd =</span> <span class="dv">15</span>,</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">sample_size =</span> <span class="dv">16</span>,</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>         <span class="at">power =</span> <span class="cn">NULL</span>,</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>         <span class="at">alternative =</span> <span class="st">&quot;less&quot;</span>,</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>         <span class="at">alpha =</span> <span class="fl">0.05</span>,</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>         <span class="at">spec =</span> <span class="fl">0.005</span>)</span></code></pre></div>
<pre><code>## [1] 0.5819579</code></pre>
<p><code>TD_power()</code> can also be used to calculate required sample size for a
desired level of power. For example, if we specify a desired power level of 0.6,
leave <code>sample_size</code> to its default and let the rest of the arguments
be as in the previous example, we see from the output of the function that
power will not increase more than 0.5% for any additional participant after a sample
size of 15. That is, the algorithm stops searching
when this level of specificity has been reached and we are nearing the
asymptotic maximum power for this effect size. We can increase the specificity
by lowering the <code>spec</code> argument.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="fu">TD_power</span>(<span class="at">case =</span> <span class="dv">70</span>,</span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>         <span class="at">mean =</span> <span class="dv">100</span>,</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">sd =</span> <span class="dv">15</span>,</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">sample_size =</span> <span class="cn">NULL</span>,</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>         <span class="at">power =</span> <span class="fl">0.6</span>,</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>         <span class="at">alternative =</span> <span class="st">&quot;less&quot;</span>,</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>         <span class="at">alpha =</span> <span class="fl">0.05</span>,</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>         <span class="at">spec =</span> <span class="fl">0.005</span>)</span></code></pre></div>
<pre><code>## Power (0.578) will not increase more than 0.5% per participant for n &gt; 15</code></pre>
<pre><code>##    n     power
## 1 15 0.5780555</code></pre>
<p>Power calculators for the Bayesian tests of deficit cannot calculate
required sample size. This is because they rely on simulation methods
to estimate approximate power and deploying a search algorithm to find the required sample
size for a given level of power would be computationally too intense. The syntax
is otherwise relatively similar to that of <code>TD_power()</code>. For <code>BTD_power()</code>
we have the two extra arguments <code>nsim</code> and <code>iter</code>, indicating the number
of simulations used in the power function and by <code>BTD()</code>, respectively.</p>
<div class="sourceCode" id="cb24"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">BTD_power</span>(<span class="at">case =</span> <span class="dv">70</span>,</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>         <span class="at">mean =</span> <span class="dv">100</span>,</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>         <span class="at">sd =</span> <span class="dv">15</span>,</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>         <span class="at">sample_size =</span> <span class="dv">15</span>,</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>         <span class="at">alternative =</span> <span class="st">&quot;less&quot;</span>,</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>         <span class="at">alpha =</span> <span class="fl">0.05</span>,</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>         <span class="at">nsim =</span> <span class="dv">1000</span>,</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>         <span class="at">iter =</span> <span class="dv">1000</span>)</span></code></pre></div>
<pre><code>## [1] 0.593</code></pre>
<p>The only difference in syntax of <code>BTD_cov_power()</code> is due to the inclusion of covariates.
The variate of interest must be specified as a vector where the first element
gives the mean and the second the standard deviation in the argument <code>control_task</code>.
The covariates can be specified similarly or as an <span class="math inline">\(m \times 2\)</span> matrix where the first
column gives the means of each covariate and the second column gives the standard
deviations. The correlation matrix of the variates must be given as well. In the example
below, power is evaluated for a test taking two covariates into account, both with a mean
of 0 and a standard deviation of 1. The correlation is specified as a <span class="math inline">\(3\times 3\)</span>
matrix with pairwise correlations of <span class="math inline">\(0.3\)</span>. The default settings include only one
covariate having a <span class="math inline">\(0.3\)</span> correlation with the variate of interest.
This function is computationally intense and hence, the number
of simulations has, for the example below, been decreased.</p>
<div class="sourceCode" id="cb26"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a>covars <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>,</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a>                   <span class="dv">0</span>, <span class="dv">1</span>), <span class="at">ncol =</span> <span class="dv">2</span>, <span class="at">byrow =</span> <span class="cn">TRUE</span>)</span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="fu">BTD_cov_power</span>(<span class="at">case =</span> <span class="sc">-</span><span class="dv">2</span>,</span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>              <span class="at">case_cov =</span> <span class="fu">c</span>(<span class="fl">0.2</span>, <span class="sc">-</span><span class="fl">0.6</span>),</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>              <span class="at">control_task =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>              <span class="at">control_covar =</span> covars,</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>              <span class="at">cor_mat =</span> <span class="fu">diag</span>(<span class="dv">3</span>) <span class="sc">+</span> <span class="fl">0.3</span> <span class="sc">-</span> <span class="fu">diag</span>(<span class="fu">c</span>(<span class="fl">0.3</span>, <span class="fl">0.3</span>, <span class="fl">0.3</span>)),</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a>              <span class="at">sample_size =</span> <span class="dv">15</span>,</span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a>              <span class="at">alternative =</span> <span class="st">&quot;less&quot;</span>,</span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>              <span class="at">alpha =</span> <span class="fl">0.05</span>,</span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>              <span class="at">nsim =</span> <span class="dv">100</span>,</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>              <span class="at">iter =</span> <span class="dv">100</span>)</span></code></pre></div>
<pre><code>## [1] 0.5</code></pre>
<p>For the difference tests one must supply the expected case scores on both
variates as well as sample size. The means and standard deviations of the
control sample can also be specified. If unspecified, they take on the default values of
0 and 1 respectively, so that the expected case scores are interpreted as
distances from the means in standard deviations. <code>RSDT_power()</code>,
<code>BSDT_power()</code> and <code>UDT_power()</code> additionally require an estimate of
the sample correlation between the variates of interest, <code>r_ab</code>. If this is
not specified a correlation of 0.5 is assumed by default. For
<code>BSDT_cov_power()</code> the correlation matrix between the variates of interest
and the covariates must instead be supplied (i.e., at least a <span class="math inline">\(3\times3\)</span> matrix
where the first correlation is the correlation between the variates of
interest).</p>
<p>The alternative hypothesis is by default assumed to be
<code>&quot;two.sided&quot;</code> since the direction of the effect is dependent on the
order of the inputs, but can be specified to be <code>&quot;less&quot;</code> or
<code>&quot;greater&quot;</code> as well. The syntax is similar for all three functions but with small
differences. For <code>UDT_power()</code> one can request required sample size for a
desired power, as for <code>TD_power()</code>. Calculators for the Bayesian tests
have the extra argument <code>calibrated</code> as to be able to specify the prior.
<code>BSDT_cov_power()</code> requires input in the same format as <code>BTD_cov_power()</code>
for both <code>control_tasks</code> and <code>control_covar</code>. The two examples
below demonstrate usage for <code>RSDT_power()</code> and <code>BSDT_cov_power()</code>.</p>
<div class="sourceCode" id="cb28"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span class="fu">RSDT_power</span>(<span class="at">case_a =</span> <span class="dv">70</span>,</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a>           <span class="at">case_b =</span> <span class="dv">55</span>,</span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a>           <span class="at">mean_a =</span> <span class="dv">100</span>,</span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>           <span class="at">mean_b =</span> <span class="dv">50</span>,</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>           <span class="at">sd_a =</span> <span class="dv">15</span>,</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>           <span class="at">sd_b =</span> <span class="dv">10</span>,</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>           <span class="at">r_ab =</span> <span class="fl">0.5</span>,</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a>           <span class="at">sample_size =</span> <span class="dv">15</span>,</span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a>           <span class="at">alternative =</span> <span class="st">&quot;two.sided&quot;</span>,</span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>           <span class="at">alpha =</span> <span class="fl">0.05</span>,</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>           <span class="at">nsim =</span> <span class="dv">1000</span>)</span></code></pre></div>
<pre><code>## [1] 0.607</code></pre>
<div class="sourceCode" id="cb30"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>cor_mat <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">1</span>,   <span class="fl">0.5</span>, <span class="fl">0.6</span>,</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a>                    <span class="fl">0.5</span>,   <span class="dv">1</span>, <span class="fl">0.3</span>,</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a>                    <span class="fl">0.6</span>, <span class="fl">0.3</span>,   <span class="dv">1</span>), <span class="at">ncol =</span> <span class="dv">3</span>, <span class="at">byrow =</span> <span class="cn">TRUE</span>)</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a><span class="fu">BSDT_cov_power</span>(<span class="at">case_tasks =</span> <span class="fu">c</span>(<span class="dv">70</span>, <span class="dv">55</span>),</span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a>               <span class="at">case_cov =</span> <span class="dv">65</span>,</span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a>               <span class="at">control_tasks =</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">100</span>, <span class="dv">15</span>,</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>                                        <span class="dv">50</span>, <span class="dv">10</span>), <span class="at">ncol =</span> <span class="dv">2</span>, <span class="at">byrow =</span> <span class="cn">TRUE</span>),</span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>               <span class="at">control_covar =</span> <span class="fu">c</span>(<span class="dv">50</span>, <span class="dv">25</span>),</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>               <span class="at">cor_mat =</span> cor_mat,</span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>               <span class="at">sample_size =</span> <span class="dv">15</span>,</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>               <span class="at">alternative =</span> <span class="st">&quot;two.sided&quot;</span>,</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a>               <span class="at">alpha =</span> <span class="fl">0.05</span>,</span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a>               <span class="at">nsim =</span> <span class="dv">100</span>,</span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>               <span class="at">iter =</span> <span class="dv">100</span>,</span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a>               <span class="at">calibrated =</span> <span class="cn">TRUE</span>)</span></code></pre></div>
<pre><code>## [1] 0.74</code></pre>
</div>
</div>
</div>
<div id="summary" class="section level1" number="4">
<h1><span class="header-section-number">4</span> Summary</h1>
<p>The <code>singcar</code>package for<code>R</code> has been outlined and
its main functionalities described. The package consists of methods for
estimating abnormality of a single case when compared to a population estimated
by a small sample. Methods for estimating abnormality on a single variate have been
described as well as methods for estimating abnormality of the difference
between two variates. Historically, the use of these tests has mainly been
within the field of neuropsychology, but their potential applicability is far
wider, extending to other areas of psychology and perhaps even to completely new
fields.</p>
<p>In neuropsychology the methods developed by John Crawford and Paul Garthwaite
are frequently used, especially the test of deficit, Equation <a href="#eq:TD">(2.1)</a>, and
the revised standardised difference test, Equation <a href="#eq:RSDT">(2.5)</a>. However, the
Bayesian standardised difference test, which outperforms the RSDT regarding
control of Type I errors, has not gained as much traction. Neither have the more
flexible Bayesian methods allowing for the inclusion of covariates.
It is hoped that by providing them in a documented package for a
popular language such as<code>R</code>, they will receive further uptake.</p>
<p>The methods described have been developed for keeping transparent control over
Type I errors, but power calculators have been implemented in the
package as well. Consideration of power can assist researchers in study design
and in setting realistic expectations for what these types of statistical
hypothesis tests can achieve <span class="citation">(<a href="#ref-mcintoshPowerCalculationsSinglecase2020" role="doc-biblioref">McIntosh and Rittmo 2020</a>)</span>.</p>
<div id="refs" class="references csl-bib-body hanging-indent">
<div id="ref-bergerObjectivePriorsBivariate2008" class="csl-entry">
Berger, James O., and Dongchu Sun. 2008. <span>“Objective <span>Priors</span> for the <span>Bivariate</span> <span>Normal</span> <span>Model</span>.”</span> <em>The Annals of Statistics</em> 36 (2): 963–82. <a href="https://www.jstor.org/stable/25464652">https://www.jstor.org/stable/25464652</a>.
</div>
<div id="ref-buckinghamGettingGripHeaviness2014" class="csl-entry">
Buckingham, Gavin. 2014. <span>“Getting a Grip on Heaviness Perception: A Review of Weight Illusions and Their Probable Causes.”</span> <em>Experimental Brain Research</em> 232 (6): 1623–29. <a href="https://doi.org/10.1007/s00221-014-3926-9">https://doi.org/10.1007/s00221-014-3926-9</a>.
</div>
<div id="ref-cohenStatisticalPowerAnalysis1988" class="csl-entry">
Cohen, J. 1988. <em>Statistical <span>Power</span> <span>Analysis</span> for the <span>Behavioral</span> <span>Sciences</span></em>. Lawrence Erlbaum Associates.
</div>
<div id="ref-crawfordInvestigationSingleCase2002" class="csl-entry">
Crawford, John, and Paul Garthwaite. 2002. <span>“Investigation of the Single Case in Neuropsychology: Confidence Limits on the Abnormality of Test Scores and Test Score Differences.”</span> <em>Neuropsychologia</em> 40 (8): 1196–1208. <a href="https://doi.org/10.1016/S0028-3932(01)00224-X">https://doi.org/10.1016/S0028-3932(01)00224-X</a>.
</div>
<div id="ref-crawfordTestingSuspectedImpairments2005" class="csl-entry">
———. 2005. <span>“Testing for <span>Suspected</span> <span>Impairments</span> and <span>Dissociations</span> in <span>Single</span>-<span>Case</span> <span>Studies</span> in <span>Neuropsychology</span>: <span>Evaluation</span> of <span>Alternatives</span> <span>Using</span> <span>Monte</span> <span>Carlo</span> <span>Simulations</span> and <span>Revised</span> <span>Tests</span> for <span>Dissociations</span>.”</span> <em>Neuropsychology</em> 19 (3): 318–31. <a href="https://doi.org/10.1037/0894-4105.19.3.318">https://doi.org/10.1037/0894-4105.19.3.318</a>.
</div>
<div id="ref-crawfordMethodsTestingDeficit2006" class="csl-entry">
———. 2006. <span>“Methods of Testing for a Deficit in Single-Case Studies: <span>Evaluation</span> of Statistical Power by <span>Monte</span> <span>Carlo</span> Simulation.”</span> <em>Cognitive Neuropsychology</em> 23 (6): 877–904. <a href="https://doi.org/10.1080/02643290500538372">https://doi.org/10.1080/02643290500538372</a>.
</div>
<div id="ref-crawfordComparisonSingleCase2007" class="csl-entry">
———. 2007. <span>“Comparison of a Single Case to a Control or Normative Sample in Neuropsychology: <span>Development</span> of a <span>Bayesian</span> Approach.”</span> <em>Cognitive Neuropsychology</em> 24 (4): 343–72. <a href="https://doi.org/10.1080/02643290701290146">https://doi.org/10.1080/02643290701290146</a>.
</div>
<div id="ref-crawfordSinglecaseResearchNeuropsychology2012" class="csl-entry">
———. 2012. <span>“Single-Case Research in Neuropsychology: <span>A</span> Comparison of Five Forms of t-Test for Comparing a Case to Controls.”</span> <em>Cortex</em> 48 (8): 1009–16. <a href="https://doi.org/10.1016/j.cortex.2011.06.021">https://doi.org/10.1016/j.cortex.2011.06.021</a>.
</div>
<div id="ref-crawfordComparingSingleCase2009" class="csl-entry">
Crawford, John, Paul Garthwaite, and D Howell. 2009. <span>“On Comparing a Single Case with a Control Sample: <span>An</span> Alternative Perspective.”</span> <em>Neuropsychologia</em> 47 (13): 2690–95. <a href="https://doi.org/10.1016/j.neuropsychologia.2009.04.011">https://doi.org/10.1016/j.neuropsychologia.2009.04.011</a>.
</div>
<div id="ref-crawfordInferentialMethodsComparing2004" class="csl-entry">
Crawford, John, Paul Garthwaite, D Howell, and C Gray. 2004. <span>“Inferential Methods for Comparing a Single Case with a Control Sample: Modified t-Tests Versus Mycroft Et Al.’s (2002) Modified Anova.”</span> <em>Cognitive Neuropsychology</em> 21 (7): 750–55. <a href="https://doi.org/10.1080/02643290342000276">https://doi.org/10.1080/02643290342000276</a>.
</div>
<div id="ref-crawfordPointIntervalEstimates2010" class="csl-entry">
Crawford, John, Paul Garthwaite, and S Porter. 2010. <span>“Point and Interval Estimates of Effect Sizes for the Case-Controls Design in Neuropsychology: <span>Rationale</span>, Methods, Implementations, and Proposed Reporting Standards.”</span> <em>Cognitive Neuropsychology</em> 27 (3): 245–60. <a href="https://doi.org/10.1080/02643294.2010.513967">https://doi.org/10.1080/02643294.2010.513967</a>.
</div>
<div id="ref-crawfordComparingSingleCase2011" class="csl-entry">
Crawford, John, Paul Garthwaite, and K Ryan. 2011. <span>“Comparing a Single Case to a Control Sample: <span>Testing</span> for Neuropsychological Deficits and Dissociations in the Presence of Covariates.”</span> <em>Cortex</em> 47 (10): 1166–78. <a href="https://doi.org/10.1016/j.cortex.2011.02.017">https://doi.org/10.1016/j.cortex.2011.02.017</a>.
</div>
<div id="ref-crawfordComparingIndividualTest1998" class="csl-entry">
Crawford, John, and D Howell. 1998. <span>“Comparing an <span>Individual</span>’s <span>Test</span> <span>Score</span> <span>Against</span> <span>Norms</span> <span>Derived</span> from <span>Small</span> <span>Samples</span>.”</span> <em>The Clinical Neuropsychologist</em> 12 (4): 482–86. <a href="https://doi.org/10.1076/clin.12.4.482.7241">https://doi.org/10.1076/clin.12.4.482.7241</a>.
</div>
<div id="ref-crawfordPayneJonesRevisited1998" class="csl-entry">
Crawford, John, D Howell, and Paul Garthwaite. 1998. <span>“Payne and <span>Jones</span> <span>Revisited</span>: <span>Estimating</span> the <span>Abnormality</span> of <span>Test</span> <span>Score</span> <span>Differences</span> <span>Using</span> a <span>Modified</span> <span>Paired</span> <span>Samples</span> t <span>Test</span>.”</span> <em>Journal of Clinical and Experimental Neuropsychology</em> 20 (6): 898–905. <a href="https://doi.org/10.1076/jcen.20.6.898.1112">https://doi.org/10.1076/jcen.20.6.898.1112</a>.
</div>
<div id="ref-dijkermanVisuomotorPerformancePatient2004a" class="csl-entry">
Dijkerman, H.Chris, Sandra Lê, Jean-François Démonet, and A.David Milner. 2004. <span>“Visuomotor Performance in a Patient with Visual Agnosia Due to an Early Lesion.”</span> <em>Cognitive Brain Research</em> 20 (1): 12–25. <a href="https://doi.org/10.1016/j.cogbrainres.2003.12.007">https://doi.org/10.1016/j.cogbrainres.2003.12.007</a>.
</div>
<div id="ref-garthwaiteDistributionDifferenceTwo2004" class="csl-entry">
Garthwaite, Paul, and John Crawford. 2004. <span>“The Distribution of the Difference Between Two t-Variates.”</span> <em>Biometrika</em> 91 (4): 987–94.
</div>
<div id="ref-gelmanBayesianDataAnalysis2013" class="csl-entry">
Gelman, A., J. B. Carlin, H. S. Stern, D. B. Dunson, A. Vehtari, and D. B. Rubin. 2013. <em>Bayesian <span>Data</span> <span>Analysis</span>, <span>Third</span> <span>Edition</span></em>. Chapman &amp; <span>Hall</span>/<span>CRC</span> <span>Texts</span> in <span>Statistical</span> <span>Science</span>. Taylor &amp; Francis. <a href="https://books.google.se/books?id=ZXL6AQAAQBAJ">https://books.google.se/books?id=ZXL6AQAAQBAJ</a>.
</div>
<div id="ref-hassanSizeweightIllusionVisual2020" class="csl-entry">
Hassan, Eleanor K, Anna Sedda, Gavin Buckingham, and Robert D McIntosh. 2020. <span>“The Size-Weight Illusion in Visual Form Agnosic Patient <span>DF</span>.”</span> <em>Neurocase</em>, August, 1–8. <a href="https://doi.org/10.1080/13554794.2020.1800748">https://doi.org/10.1080/13554794.2020.1800748</a>.
</div>
<div id="ref-mcintoshPowerCalculationsSinglecase2020" class="csl-entry">
McIntosh, Robert D., and Jonathan Ö. Rittmo. 2020. <span>“Power Calculations in Single-Case Neuropsychology: <span>A</span> Practical Primer.”</span> <em>Cortex</em> 135: 146–58. <a href="https://doi.org/10.1016/j.cortex.2020.11.005">https://doi.org/10.1016/j.cortex.2020.11.005</a>.
</div>
<div id="ref-payneStatisticsInvestigationIndividual1957" class="csl-entry">
Payne, R. W., and H. G. Jones. 1957. <span>“Statistics for the Investigation of Individual Cases.”</span> <em>Journal of Clinical Psychology</em> 13 (2): 115–21.
</div>
<div id="ref-rcoreteamLanguageEnvironmentStatistical2020" class="csl-entry">
R Core Team. 2020. <em>R: <span>A</span> <span>Language</span> and <span>Environment</span> for <span>Statistical</span> <span>Computing</span></em>. Vienna, Austria: R Foundation for Statistical Computing. <a href="https://www.R-project.org/">https://www.R-project.org/</a>.
</div>
<div id="ref-shalliceNeuropsychologyMentalStructure1988" class="csl-entry">
Shallice, Tim. 1988. <em>From Neuropsychology to Mental Structure</em>. Cambridge: Cambridge University Press.
</div>
<div id="ref-sokalBiometryPrinciplesPractice1981" class="csl-entry">
Sokal, R. R., and F. J. Rohlf. 1981. <em>Biometry: <span>The</span> <span>Principles</span> and <span>Practice</span> of <span>Statistics</span> in <span>Biological</span> <span>Research</span></em>. W. H. Freeman. <a href="https://books.google.co.uk/books?id=C-OTQgAACAAJ">https://books.google.co.uk/books?id=C-OTQgAACAAJ</a>.
</div>
<div id="ref-tiaoBayesianEstimationMultivariate1964" class="csl-entry">
Tiao, George C., and Arnold Zellner. 1964. <span>“On the <span>Bayesian</span> <span>Estimation</span> of <span>Multivariate</span> <span>Regression</span>.”</span> <em>Journal of the Royal Statistical Society: Series B (Methodological)</em> 26 (2): 277–85. https://doi.org/<a href="https://doi.org/10.1111/j.2517-6161.1964.tb00560.x">https://doi.org/10.1111/j.2517-6161.1964.tb00560.x</a>.
</div>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
